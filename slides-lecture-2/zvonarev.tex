\documentclass[unicode, notheorems]{beamer}

% If you have more than three sections or more than three subsections in at least one section,
% you might want to use the [compress] switch. In this case, only the current (sub-) section
% is displayed in the header and not the full overview.
\mode<presentation>
{
  \usetheme[numbers, totalnumbers, compress]{Statmod}

  \setbeamercovered{transparent}
  % or whatever (possibly just delete it)
}

%\usepackage{pscyr}
\usepackage[T2A]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsthm}
\usepackage{mathdots}


%\usepackage{tikz}
% you only need this when using TikZ graphics

\newtheorem{theorem}{Теорема}
\newtheorem{example}{Пример}
\newtheorem{definition}{Определение}
\newtheorem{thnote}{Замечание}
\newtheorem{proposition}{Утверждение}
\newtheorem{solution}{Решение}

\DeclareMathOperator{\mathspan}{span}
\def\dist{\mathop{\mathrm{dist}}}

\input{letters}

\title{Аппроксимация временными рядами конечного ранга}

\author{Звонарев Никита, гр. 522}
\institute[СПбГУ]{Санкт-Петербургский государственный университет \\
    Математико-механический факультет \\
    Кафедра статистического моделирования \\
    \vspace{0.2cm}
    Научный руководитель: к.ф.-м.н., доц. Голяндина Н. Э. \\
    \vspace{0.2cm}
    Рецензент: к.ф.-м.н., доц. Коробейников А. И. \\
    \vspace{0.2cm}
}
\date{
    Санкт-Петербург\\
    2015г.
}

\subject{Beamer}
\setbeamertemplate{bibliography item}{[\theenumiv]}
% This is only inserted into the PDF information catalog. Can be left
% out.

% Delete this, if you do not want the table of contents to pop up at
% the beginning of each subsection:
% \AtBeginSubsection[]
% {
%   \begin{frame}<beamer>
%     \frametitle{Outline}
%     \tableofcontents[currentsection,currentsubsection]
%   \end{frame}
% }

\begin{document}

\begin{frame}
    \titlepage
\end{frame}

\begin{frame}
	\frametitle{Постановка задачи}
	\begin{itemize}
		\item Дано: $\tsX$ --- временной ряд, $\tsX \in \calX_N$ --- множество всех временных рядов длины $N$.
		\item $\calX_N^r$ --- подмножество $\calX_N$ рядов \structure{некоторой структуры}.
		\item Найти: 
		\begin{equation} \label{maintask}
				f_q(\tsY) \to \min_{\tsY \in \calX_N^r}, \quad f_q(\tsY) = \sum \limits_{i=1}^N q_i(x_i - y_i)^2,
		\end{equation} 
		$q_i \ge 0$ --- неотрицательные веса.
		\item Приложение в статистике: наблюдаем $\tsX$ = $\tsY$ + $\tsN$, где $\tsY \in \calX_N^r$ --- сигнал, $\tsN$ --- белый шум с нулевым матожиданием. Требуется найти оценку для $\tsY$. В качестве оценки можно рассматривать решение задачи \eqref{maintask}.
	\end{itemize}
	
\end{frame}

\begin{frame}
	\frametitle{Ряды, управляемые ЛРФ}
	\begin{definition}
		Ряд, управляемый линейной рекуррентной формулой порядка~$r$: $\tsX = (x_1, \ldots, x_N), \quad x_n = \sum_{i = 1}^{r} a_i x_{n-i}, \quad n = r + 1, \ldots, N.$
	\end{definition}
	Параметрический вид:
	\begin{equation*}
	x_n = \sum_i P_i(n) \exp(\alpha_i n) \cos(2 \pi \omega_i n + \psi_i).
	\end{equation*}
	
	Можно показать эквивалентность поиска ряда, управляемого ЛРФ, и поиска ряда конечного $L$-ранга при наложении дополнительных условий.
\end{frame}

\begin{frame}
	\frametitle{Структура сигнала}
	
	Временной ряд $\tsX = (x_1, \ldots, x_N)$.
	
	Параметры: $1 < L < N$ --- \emph{длина окна}, $K = N - L + 1$, $0 \le r \le L$ --- ранг.
	
	Вектора вложения: $X_i = (x_i, \ldots, x_{i + L - 1})^\rmT, \qquad i = 1, \ldots, K$.
	\begin{definition}
		Траекторное пространство: $\spX^{(L)}(\tsX) = \spX^{(L)} = \mathspan(X_1, \ldots, X_K).$
	\end{definition}
	\begin{definition}
		$L$-ранг ряда $\tsX$ равен $r$ $\Leftrightarrow$ $\dim \spX^{(L)} = r$.
	\end{definition}
	
	$\calX_N$ --- множество всех временных рядов длины $N$. $\calX_N^r$ --- множество всех временных рядов длины $N$ $L$-ранга, не превосходящего $r$.
\end{frame}

\begin{frame}
	\frametitle{Постановка на матричном языке}
	\begin{enumerate}
		\item Временной ряд $\tsX = (x_1, \ldots, x_N)$.
		\item $\bfX = \calT(\tsX)$, где $\calT$ --- биективное отображение на множество траекторных матриц:
		\begin{equation*}
		\bfX = \begin{pmatrix}
		x_1 & x_2 & \cdots & x_K \\ 
		x_2 & \iddots & \iddots & x_{K+1} \\ 
		\vdots & \iddots & \vdots & \vdots \\ 
		x_L & x_{L+1} & \cdots & x_N
		\end{pmatrix} 
		\end{equation*}
		\item Найти $\bfY$: $||\bfX - \bfY||_? \to \min$, $\bfY \in \calH \cap \calM_r$, где $\calH$ --- множество ганкелевых матриц, $\calM_r$ --- матрицы ранга $\le r$.
		\item $\tsY = \calT^{-1}(\bfY)$
	\end{enumerate}
\end{frame}

\section{Способ решения}
\subsection{Теоретические сведения}
\begin{frame}
	\frametitle{Стандартное решение}
	$\bfY$: $||\bfX - \bfY||_? \to \min$, $\bfY \in \calH \cap \calM_r$, где $\calH \subset \sfR^{L \times K}$ --- множество ганкелевых матриц, $\calM_r \subset \sfR^{L \times K}$ --- матрицы ранга~$\le r$.
	
	\begin{solution}
		
		Переменные проекции: 
		\begin{equation*}
		\bfY = (\Pi_\calH \circ \Pi_{\calM_r})^I (\bfX),
		\end{equation*}
		$\Pi_\calH$ --- проектор на ганкелевы матрицы, $\Pi_{\calM_r}$ --- проектор на матрицы ранга $\le r$.
	\end{solution}
	\begin{enumerate}
	\item Интересует сходимость к нужному множеству
	\item Выбор норм тоже интересен
    \end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Предварительные утверждения}
	\begin{itemize} \small
		\item Доказательство расширено на случай абстрактного гильбертового пространства 
		\item Ключевое свойство -- ``конусность'' соответствующих подмножеств. В \cite{Cadzow1988} используется другое доказательство
	\end{itemize}
	%$\bfY = (\Pi_\calH \circ \Pi_{\calM_r})^I (\bfX)$, $\Pi_\calH$ --- проектор на ганкелевы матрицы, $\Pi_{\calM_r}$ --- проектор на матрицы ранга $\le r$ по норме $||\cdot||$.
	
	Рассмотрим $\sfX$ -- гильбертово пространство со скалярным произведением $\langle \cdot, \cdot \rangle$, $\calH$ --- замкнутое (топологически) линейное подпространство. $\calM$ --- ни линейное, ни выпуклое замкнутое множество. Тем не менее, $\calM$ замкнуто относительно умножения на константу, т.е. если $z \in \calM$, то $\alpha z \in \calM$ для любой $\alpha \in \sfR$.
	
	Требуется спроектировать заданную точку $x$ на $\calH \cap \calM$, т.е. решить следующую задачу: $\|x - y\| \to \min_y$ где $y \in \calH \cap \calM$, $\|\cdot\|$ -- норма, порождённая скалярным произведением.
	\bibliography{zvonarev}
\end{frame}

\begin{frame}
	\frametitle{``Теорема Пифагора''}
	\begin{proposition}
		Пусть $\sf$ --- гильбертово пространство, $\calM \subset \sfX$ --- замкнутое относительно умножения на константу подпространство, $\Pi_\calM$ --- проектор на $\calM$. Тогда для любого $x \in \calX$ выполнено следующее равенство (``теорема Пифагора''):
		\begin{equation*} 
		\|x\|^2~=~\|x~-~\Pi_\calM x\|^2~+~\|\Pi_\calM x\|^2.
		\end{equation*}
	\end{proposition}
\end{frame}

%\begin{frame}
%	\frametitle{Замкнутость $\calM_r$}
%	\begin{proposition} \small
%		Множество матриц ранга $\le r$ $\calM_r$ замкнуто в топологии, порожденной фробениусовской нормой.
%	\end{proposition}
	
%	\begin{proof} \small
%		Рассмотрим функцию-``индикатор'' $f: \sfR^{L \times K} \to \sfR$, определенную как \begin{equation*}
%		f(\bfX) = \sum_{\bfU \in \sfU(\bfX)} |\det(\bfU)|,
%		\end{equation*}
%		где $\sfU(\bfX)$ --- множество всевозможных квадратных подматриц порядка $r+1$ матрицы $\bfX$. Заметим, что $f$ --- непрерывная, и $\bfX \in \calM_r \Leftrightarrow f(\bfX) = 0$.
		
%		$\bfX_1, \bfX_2, \ldots$ --- сходящаяся последовательность, $\bfX_k \in \calM_r$ $\forall k$, $\bfX'$ --- ее предел. Тогда $f(\bfX_k) = 0$ $\forall k$; используя непрерывность $f$, получаем $f(\bfX') = 0$.
%	\end{proof}	
%\end{frame}

\begin{frame}
	\frametitle{Основная теорема}
	Рассмотрим один шаг алгоритма:
	$y_{k+1}=\Pi_\calH \Pi_\calM y_{k}, \mbox{\ где\ } y_{0}=x.$
	\begin{theorem}
			 Пусть выполнены условия Утверждения, а также множество $\calM$ и подпространство $\calH$ топологически замкнуты. Тогда
			\begin{enumerate}
				\item $\|y_k - \Pi_{\calM} y_k\| \to 0$ при $k \to +\infty$, $\|\Pi_{\calM}y_k - y_{k+1}\| \to 0$ при $k \to +\infty$.
				\item Пусть $\calM \cap B_1$ является компактом, где $B_1 = \{z: \|z\| \le 1\}$~---~замкнутый единичный шар. Тогда существует сходящаяся подпоследовательность точек $y_{i_1}, y_{i_2}, \ldots$ такая, что ее предел $y^*$  лежит в $\calM \cap \calH$.
			\end{enumerate}
	\end{theorem}
\end{frame}

\begin{frame}
	\frametitle{Замечания}
	Применяем Теорему к нашему случаю: $\sfX = \sfR^{L \times K}$, $\calH$~---~ганкелевы матрицы, $\calM_r$ --- матрицы ранга $\le r$.
	
	\vspace{0.2cm}
	
	Соответствующий вид переменных проекций:
	\begin{equation*}
	\bfY_{k+1}=\Pi_\calH \Pi_{\calM_r} \bfY_{k}, \mbox{\ где\ } \bfY_{0}=\bfX \in \sfR^{L\times K}.
	\end{equation*}
	
	\vspace{0.2cm}
	
	$\calM_r$ замкнуто при любой матричной норме.
	
	\vspace{0.2cm}
	
	В дальнейшем, мы будем рассматривать нормы, порожденные следующими взвешенными фробениусовскими скалярными произведениями: 
	\begin{equation*}
	\langle\bfY, \bfZ\rangle_M = \sum_{l = 1}^L \sum_{k = 1}^K m_{l, k} y_{l, k} z_{l, k}, \quad \text{где все} \; m_{l,k} \ge 0.
	\end{equation*}
	Для эквивалентности норм необходимо, чтобы все $m_{l,k} > 0$.
	
\end{frame}

\subsection{Нормы и алгоритмы}
\begin{frame}
	\frametitle{Стандартное решение}
	$\bfY$: $||\bfX - \bfY||_? \to \min$, $\bfY \in \calH \cap \calM_r$, где $\calH$ --- множество ганкелевых матриц, $\calM_r$ --- матрицы ранга $\le r$.
	
	\begin{solution}
		
		Переменные проекции: 
		\begin{equation*}
		\bfY = (\Pi_\calH \circ \Pi_{\calM_r})^I (\bfX),
		\end{equation*}
		$\Pi_\calH$ --- проектор на ганкелевы матрицы, $\Pi_{\calM_r}$ --- проектор на матрицы ранга $\le r$.
	\end{solution}
	
	$\Pi_\calH$ и $\Pi_{\calM_r}$ зависят от $||\cdot||_?$. Варианты:
	\begin{enumerate}
		\item $||\bfX||_M^2 = \sum_{l = 1}^L \sum_{k = 1}^K m_{l, k} (x_{l, k})^2$, все $m_{l, k} \ge 0$
		\item Частный случай предыдущего пункта: $m_{l, k} = 1$.
		\item $||\bfX||_\bfC^2 = \text{tr}(\bfX \bfC \bfX^\rmT)$, $\bfC$ --- симметричная, неотрицательно определенная матрица порядка $K \times K$.
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Эквивалентность скалярных произведений и норм}
	\begin{enumerate}
		\item $<\tsX, \tsY>_q = \sum_{i=1}^N q_i x_i  y_i$
		\item $<\bfX, \bfY>_M = \sum_{l = 1}^L \sum_{k = 1}^K m_{l, k} x_{l, k} y_{l, k}$
		\item $<\bfX, \bfY>_\bfC = \text{tr}(\bfX \bfC \bfY^\rmT)$.
	\end{enumerate}
	\begin{proposition}
		\small
	    \begin{enumerate}
		\item Пусть $\bfX = \calT(\tsX)$,  $\bfY = \calT(\tsY)$. Тогда $<\tsX,\tsY>_q= <\bfX,\bfY>_M$ тогда и только тогда, когда
		\begin{equation*}
		q_i = \sum_{\substack{1 \le l \le L \\ 1 \le k \le K \\ l+k-1=i}} m_{l,k}.
		\end{equation*}
		
		\item Для диагональной матрицы $\bfC$, $<\bfX,\bfY>_M= <\bfX,\bfY>_\bfC$ тогда и только тогда, когда
		\begin{equation*}
		m_{l,k}=c_{k,k}.
		\end{equation*}
	    \end{enumerate}
	\end{proposition}
	
\end{frame}

\begin{frame}
	\frametitle{Проектор $\Pi_{\calM_r}$}
	Варианты:
	\begin{enumerate}
		\item $||\bfX||_M$, общий случай: EM-подобный алгоритм.
		\vspace{0.2cm}
        \item $||\bfX||_\bfC$: косоугольное SVD-разложение. $\bfC = \bfO_{\bfC}^\rmT \bfO_\bfC$, $\bfB = \bfX \bfO_{\bfC}^\rmT$, $\Pi_{\calM_r}^\bfC(\bfX) = \Pi_{\calM_r}(\bfB)(\bfO_{\bfC}^\rmT)^\dagger$.
        \vspace{0.2cm}		
		\item $||\bfX||_M$, все $m_{l, k} = 1$: через стандартное SVD-разложение. $\Pi_{\calM_r}(\bfX) = \bfU \Sigma_r \bfV^\rmT$, где $\bfX = \bfU \Sigma \bfV^\rmT$.
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Проектор $\Pi_{\calH}$}
	Варианты:
	\begin{enumerate}
		\item $||\bfX||_M$, $m_{l,k}$ на побочных диагоналях равны, в частности $m_{l, k} = 1$: диагональное усреднение.
		\begin{equation*}
		\bfX = \Pi_{\calH}(\bfY), \quad x_{l,k} = \sum_{i + j = l + k} y_{i, j} / w_{l + k - 1}.
		\end{equation*}
		\item $||\bfX||_\bfC$, $\bfC$ --- диагональная: взвешенное диагональное усреднение с весами $c_{i, i}$, где $\bfC = (c_{i, j})$.
		
		\begin{equation*}
		\bfX = \Pi_{\calH}(\bfY), \quad x_{l,k} = \frac{\sum_{i,j:\, i+j=l+k} c_{i,i} y_{i,j}}{\sum_{i,j:\, i+j=l+k} c_{i,i}}.
		\end{equation*}
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Варианты алгоритма Cadzow}
	$||\bfX||^2_M =  \sum_{l = 1}^L \sum_{k = 1}^K m_{l, k}$
	\begin{enumerate}
		\item Все $m_{l, k} = 1$ --- базовый алгоритм Cadzow ($\Pi_{\calM_r}$ --- обычный SVD, $\Pi_\calH$ --- диаг. усреднение).
		\begin{thnote}
			Эквивалентные веса базового алгоритма:
			\begin{equation*}
			q_i = w_i = \begin{cases}
			i & \text{для $i = 1, \ldots, L-1,$}\\
			L & \text{для $i = L, \ldots, K,$}\\
			N - i + 1 & \text{для $i = K + 1, \ldots, N,$}
			\end{cases} \qquad.
			\end{equation*}
			что не всегда естественно.
		\end{thnote}
		\item $||\bfX||_M$, $m_{l, k} = 1 / w_{l + k - 1}$ --- Weighted Cadzow ($\Pi_{\calM_r}$ --- EM, $\Pi_\calH$ --- диаг. усреднение). Для него все $q_i$ = 1.
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Варианты Cadzow с косоугольным SVD}
	$||\bfX||_\bfC^2 = \text{tr}(\bfX \bfC \bfX^\rmT)$
	\begin{enumerate}
		\item $\bfC = \text{diag}(1, \alpha, \alpha, \ldots, \alpha, 1, \alpha, \ldots, 1)$,
		где единицы стоят на $1$, $L + 1$, $2L + 1$, \ldots , $K$ месте, $0 \le \alpha \le 1$ (Cadzow($\alpha$))
		\begin{theorem}
			Эквивалентные веса алгоритма Cadzow($\alpha$):
			\begin{equation*}
			q_i = \begin{cases}
			1 + (i - 1) \alpha & \text{для $i = 1, \ldots, L-1,$}\\
			1 + (L - 1) \alpha & \text{для $i = L, \ldots, K-1,$}\\
			1 + (N - i) \alpha & \text{для $i = K, \ldots, N.$}
			\end{cases}
			\end{equation*}
		\end{theorem}
		\item $\hat \bfC = \text{diag}(C)$, где $C$ --- усреднение матрицы $\bfM$, примененной в алгоритме Weighted Cadzow, по столбцам (Hat-Cadzow).
	\end{enumerate}
	
	$\Pi_{\calM_r}$ --- косоугольное SVD, $\Pi_\calH$ --- взвешенное диаг. усреднение
\end{frame}

\begin{frame}
	\frametitle{Пример весов ряда ($N = 40$, $L = 8$)}
	\begin{center}
		\includegraphics*[width = 10cm]{weights.pdf}
	\end{center}	
\end{frame}

\begin{frame}
	\frametitle{Алгоритм Extended Cadzow}
	\begin{equation*}
	\calX = \begin{pmatrix}
	&  &  & x_1 & x_2 & \cdots & x_K & x_{K+1} & \cdots & x_N \\ 
	&  & \iddots & x_2 & x_3 & \iddots & x_{K+1} & \iddots & \iddots &  \\ 
	& x_1 & \iddots & \iddots & \iddots & \iddots & \iddots & x_N &  &  \\ 
	x_1 & x_2 & \cdots & x_L & x_{L+1} & \cdots & x_N &  &  & 
	\end{pmatrix}.
	\end{equation*}
	\begin{enumerate}
		\item $q_i = 1$, $i = 1, \ldots, N$, но задача несколько иная
		\item $\tilde \calT$ : $\tilde \calT(\tsX) = \calX$ --- биекция между рядами и матрицами с пропусками.
		\item Проектор на множество матриц неполного ранга $\Pi_{\widetilde \calM_r}$ (EM-алгоритм).
		\item Проектор на множество траекторных матриц с пропусками $\Pi_\gX$ (диагональное усреднение).
		\item Сам алгоритм: $\tsY = \tilde \calT^{-1}((\Pi_\gX \circ \Pi_{\widetilde \calM_r})^I (\tilde \calT(\tsX)))$.
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Различные проблемы}
	\begin{itemize}
		\item Базовый алгоритм Cadzow --- имеет $q_i$, далекие от оптимальных
		\item Weighted, Extended Cadzow --- работает долго, так как использует итерационный EM-алгоритм для проектирования на множество матриц ранга $\le r$
		\item Cadzow($\alpha$) с косоугольным SVD: при $\alpha = 0$~--- вообще нет сходимости к нужному множеству, $\alpha \approx 0$, $\alpha > 0$: медленно сходится, проблемы со слабой разделимостью, требуется, чтобы $N$ было кратно $L$
	\end{itemize}
	\begin{equation*}
	\alpha = 0 \implies \bfC = \text{diag}(1, 0, 0, \ldots, 0, 1, 0, \ldots, 1) \quad \text{--- }
	\end{equation*}
	вырожденная матрица
\end{frame}

\section{Слабая разделимость}
\begin{frame} \small
	\frametitle{Слабая разделимость в косоугольном случае}
 $\bfC \in \sfR^{K \times K}$ --- симметричная неотрицательно определенная, $\tsX_1$ и $\tsX_2$~--- два временных ряда длины $N$, $\bfX^1$, $\bfX^2$ --- их траекторные матрицы. Определим \emph{коэффициент корреляции $i$-го и $j$-го столбца}:
\begin{equation*}
\rho^c_{i,j} = \frac{(X^1_i, X^2_j)}{\|X^1_i\| \|X^2_j\|},
\end{equation*}
где $X^k_i$ --- $i$-й столбец матрицы $\bfX^k$, $k = 1, 2$. 

\emph{Коэффициент корреляции $i$-й и $j$-й строчки}:
\begin{equation*}
\rho^r_{i,j} = \frac{(X^{1,i}, X^{2,j})_\bfC}{\|X^{1,i}\|_\bfC \|X^{2,j}\|_\bfC},
\end{equation*}
где $X^{k,i}$ --- $i$-я строка матрицы $\bfX^k$, $k = 1, 2$, а $(\cdot, \cdot)_\bfC$ --- косоугольное скалярное произведение в $\sfR^K$, порожденное матрицей $\bfC$: $(X, Y)_\bfC = X \bfC Y^\sfT$ (здесь $X$, $Y$ --- вектор-строчки), $\| \cdot \|_\bfC$ --- соответствующая норма.
\end{frame}

\begin{frame}
	\frametitle{Слабая разделимость гармоники и константы}
	\begin{definition}
		Скажем, что ряды $\tsX_1$ и $\tsX_2$ \emph{слабо $\varepsilon$-разделимы} если
		\begin{equation*}
			\rho = \max\Big(\max_{1 \le i,j \le K}|\rho^c_{i,j}|, \max_{1 \le i,j \le L}|\rho^r_{i,j}|\Big) < \varepsilon.
		\end{equation*}
	\end{definition}
	Интересует порядок $\varepsilon$ при $N \to \infty$, если брать первые $N$ точек бесконечного ряда.
	
	Будем рассматривать $\tsX_1^\infty = (\cos(2 \pi \omega k), k = 1, 2, \ldots)$ и $\tsX_2^\infty = (c, c, \ldots)$ при $L, K \to \infty$, где $N = L + K - 1$.
	
	\vspace{0.3cm}
	Известный результат: когда $\bfC$ --- единичная матрица, то $\varepsilon$ имеет порядок $1/\min(L,K)$.
\end{frame}

\begin{frame}
	\frametitle{Слабая разделимость: новые результаты}
\begin{proposition}
	Пусть $\tsX_1^\infty = (\cos(2 \pi \omega k), k = 1, 2, \ldots)$, где $0<\omega <0.5$ --- синусоида, $\tsX_2^\infty = (c, c, \ldots)$ --- константа,  $L,K \to \infty$ так, что $h = h_L = N/L$, где $N=L+K-1$, целое, и $\bfC=\bfC(\alpha)$ диагональная с диагональными элементами (алгоритм Cadzow($\alpha$)):
	\begin{equation*}
	c_k = \begin{cases}
	1, & \text{если} \quad k = jL+1 \quad \text{для некоторых} \ j = 0, \ldots, h-1,\\
	\alpha, & \text{в противном случае},
	\end{cases}
	\end{equation*}
	где $0 \le \alpha \le 1$. Тогда $\rho$ имеет порядок $\max\left(\frac{1}{L}, \frac{(1-\alpha)C_{L,K}+\alpha}{(1-\alpha)N/L+\alpha K}\right)$, где порядок $C_{L,K}$
	может меняться от $O(1)$ to $O(N/L)$ в зависимости от того, как $L$ и $K$ стремятся к бесконечности.
	\end{proposition}
    \small Если $\exists \delta,$ $0 < \delta < 0.5$: $L \omega \in [k + \delta, \, k + 1 - \delta]$ для всех целых $k$, всех $L$ из последовательности, то $C_{L, K} = O(1)$.
\end{frame}

\begin{frame}
	\frametitle{Слабая разделимость: порядок}
	\begin{itemize}
		\item Оптимальный выбор для $L$ это $L \approx \frac{\alpha(N + 1) + \sqrt{\alpha^2(N+1)^2 + 4N(1  - \alpha^2)}}{2(1 + \alpha)}$
		\item В этом случае порядок разделимости $\rho = O \left(\frac{1}{\alpha N + \sqrt{N(1 - \alpha ^ 2)}} \right)$
		\item Для фиксированного $\alpha$ порядок разделимости остаётся равным $1/N$ (и $O(N/L) = O(1)$, т.к. $N/L$ ограничено)
		\item Если рассматривать $\alpha(N) = O(N^{-\beta})$, то порядок становится равным $O(N^{\beta - 1})$ для $0 \le \beta \le 0.5$, и $O(1/\sqrt{N})$ для $\beta > 0.5$.
	\end{itemize}
\end{frame}

 
\section{Эксперименты}
\begin{frame}
	\frametitle{Пример №1 (одна итерация)}
	Задача оценки сигнала: $N = 40$, $L = 20$, $r = 2$, $\tsX = (x_{1}, \ldots, x_N),$  $x_k = 5\sin{\frac{2 k \pi}{6}} + \varepsilon_k$; $\varepsilon_k$, $k = 1, \ldots N$ --- гауссовский белый шум с нулевым средним и единичной дисперсией.
	\vspace{-0.8cm}
	\begin{center}
		\includegraphics*[width = 9cm]{s1_it1.pdf}
	\end{center}
	
	
\end{frame}

\begin{frame}
	\frametitle{Пример №2 (много итераций)}
	Задача оценки сигнала: $N = 40$, $L = 20$, $r = 2$, $\tsX = (x_{1}, \ldots, x_N),$  $x_k = 5\sin{\frac{2 k \pi}{6}} + \varepsilon_k$; $\varepsilon_k$, $k = 1, \ldots N$ --- гауссовский белый шум с нулевым средним и единичной дисперсией.
	\vspace{-0.8cm}
	
	\begin{center}
		\includegraphics*[width = 9cm]{s1_it100.pdf}
	\end{center}
	
\end{frame}

\begin{frame}
	\frametitle{Пример №3}
	Задача оценки сигнала: $N = 40$, $L = 20$, $r = 2$, $\tsX = (x_{1}, \ldots, x_N),$  $x_k = 5\sin{\frac{2 k \pi}{6}} + \varepsilon_k$.
	
	\begin{center}
		\includegraphics*[width = 9cm]{cadzowspeed_2.pdf}
	\end{center}
\end{frame}

\begin{frame}
	\frametitle{Пример №4: среднее количество итераций и RMSE}
	Задача оценки сигнала: $N = 40$, $L = 20$, $r = 2$, $\tsX = (x_{1}, \ldots, x_N),$  $x_k = 5\sin{\frac{2 k \pi}{6}} + \varepsilon_k$.
	
	Критерий остановки: $\frac{\|\calT^{-1}(\bfY_k) - \calT^{-1}(\bfY_{k + 1})\|^2}{N} < 10^{-8}$
	\vspace{-0.4cm}
	\begin{center}
		\includegraphics*[width = 9cm]{2axis.pdf}
	\end{center}
\end{frame}

\begin{frame}
	\frametitle{Пример №4.5: $\sigma = 3$}
	Задача оценки сигнала: $N = 40$, $L = 20$, $r = 2$, $\tsX = (x_{1}, \ldots, x_N),$  $x_k = 5\sin{\frac{2 k \pi}{6}} + 3 \varepsilon_k$.
	
	Критерий остановки: $\frac{\|\calT^{-1}(\bfY_k) - \calT^{-1}(\bfY_{k + 1})\|^2}{N} < 10^{-8}$
	\vspace{-0.4cm}
	\begin{center}
		\includegraphics*[width = 9cm]{2axis-3.pdf}
	\end{center}
\end{frame}

\begin{frame}
	\frametitle{Пример из жизни}
    Ряд `Fortified wine', первые 168 значений.
    \begin{itemize}
    	\item Построена параметрическая модель ``похожего'' ряда с помощью SSA + ESPRIT: 
    	\small
    	\begin{multline*} 
    	s_{k} = 3997.74 (0.9967)^k +
    	1174.75 (0.9942)^k \sin(\frac{\pi k}{6} - 2.249) + \\
    	425.75 (1.0001)^k \sin(\frac{\pi k}{2} + 2.333) + 
    	211.55 (1.004)^k \sin(\frac{\pi k}{3} + 1.677) + \\
    	169.33 (1.0007)^k \sin(\frac{5 \pi k}{6} + 1.533) + 
    	361.07 (0.9884)^k \sin(\frac{2 \pi k}{3} - 2.901),
    	\end{multline*}
    	\normalsize
    	$\tsX=(x_1,\ldots,x_N)$, $x_i=s_i + 353.17 (0.9967)^k \varepsilon_i$.
    	\item С помощью моделирования получено качество оценки искусственного сигнала и точность аппроксимации ряда
    	\item Метод применён к настоящему ряду
    \end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Пример из жизни: результаты моделирования}
\begin{table}
	\caption{Сравнение методов по оценке сигнала, аппроксимации ряда `Fortifide wine' и его промоделированных копий.}
	\label{tab:rltable}
	
	\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}ccccc}
		\hline
		Метод: & $\tsS$ & $\tsX$ & $\tsX^*$ \\
		\hline
		Cadzow, $\alpha = 1$ & 127.71 & 263.20 & 283.58 \\
		\hline
		Cadzow, $\alpha = 0.8$ & 127.18 & 262.98 & 283.25 \\
		\hline
		Cadzow, $\alpha = 0.6$ & 126.42 & 262.63 & 282.72 \\
		\hline
		Cadzow, $\alpha = 0.4$ & 125.39 & 262.06 & 281.77 \\
		\hline
		Cadzow, $\alpha = 0.2$ & 124.10 & 260.94 & 279.55 \\
		\hline
		Cadzow, $\alpha = 0.1$ & 125.09 & 260.52 & 276.70 \\
		\hline
		Cadzow, $\alpha = 0.05$ & 129.44 & 261.47 & 274.00 \\
		\hline
	\end{tabular*}
\end{table}
\end{frame}

\begin{frame}
	\frametitle{Пример из жизни: наилучшее приближение}
	Получено алгоритмом Cadzow($0.2$). Пунктирная линия --- исходный ряд, сплошная линия --- аппроксимация рядом конечного ранга.
	\vspace{-0.2cm}
	\begin{center}
		\includegraphics*[width = 9cm]{rlimage.pdf}
	\end{center}
\end{frame}

\begin{frame}
	\frametitle{Пример № последний: красный и белый шум, $\sigma = 2$}
	$N = 40$, $L = 20$, $r = 2$, $\tsX = (x_{1}, \ldots, x_N),$  $x_k = 5\sin{\frac{2 k \pi}{6}} + 2 \varepsilon_k$.
	$\tsY = (y_{1}, \ldots, y_N),$  $y_k = 5\sin{\frac{2 k \pi}{6}} + 2 \gamma_k$, $\gamma_k = \varphi \gamma_{k - 1} + \sqrt{1 - \varphi^2} \epsilon_k$, $\varphi = 0.8$.
	\vspace{-0.4cm}
	\begin{center}
		\includegraphics*[width = 9cm]{2axis-2.pdf}
	\end{center}
\end{frame}

\section{Итоги}

%\begin{frame}
%  \frametitle{Выводы}
%  Рассмотрен широкий класс алгоритмов, проведено сравнение на модельном примере:
%  \begin{itemize}
%  \item Доказана сходимость по подпоследовательностям для всех алгоритмов
%  \item Единичные веса достигаются только на алгоритмах с вложенными итерациями (Extended, Weighted Cadzow), которые являются медленными.
%  \item Алгоритмы с более близкими к единичным весами дают лучшую аппроксимацию в пределе, но медленее сходятся и имеют проблемы с разделимостью:
%  
%  Cadzow($\alpha$): малое $L$, $\alpha$ $\Rightarrow$ плохая разделимость
%  \item Лучший метод среди всех -- Extended Cadzow. Среди методов без внутренних итераций на одной лучше всего работает Cadzow($1$) и Hat-Cadzow, в пределе --- Cadzow($0.1$)
%  \end{itemize}

%\end{frame}

\begin{frame}
	\frametitle{Выводы}\footnotesize
	\begin{itemize}
		\item Рассмотрен широкий класс итерац. алгоритмов решения задачи 
		%(повторить для рядов с весами $q_i$) 
		для оценивания сигнала $\tsY$  в модели $\tsX = \tsY + \tsN$.
		\item Доказана сходимость по подпоследовательностям для всех алгоритмов
		\item Единичные веса $q_i$ достигаются только на алгоритмах с вложенными итерациями (Extended, Weighted Cadzow), которые являются медленными.
		\item  На численных примерах проведено исследование и получены следующие результаты:
		\begin{itemize} \footnotesize
			\item Лучший метод среди всех -- Extended Cadzow.
			\item Алгоритмы с более близкими к единичным весами дают лучшую аппроксимацию в пределе, но медленнее сходятся и имеют проблемы с разделимостью,
			
			например, Cadzow($\alpha$) при маленькой  длине окна $L$ или малом параметре $\alpha$.
			\item На одной итерации лучше всего работает Cadzow($1$) (= Singular Spectrum Analysis) и Hat-Cadzow, т.е. методы с лучшей разделимостью.
		\end{itemize}
	\end{itemize}
	
\end{frame}

\bibliographystyle{plain}

\end{document}