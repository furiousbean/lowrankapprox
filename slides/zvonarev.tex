\documentclass[unicode, notheorems]{beamer}

% If you have more than three sections or more than three subsections in at least one section,
% you might want to use the [compress] switch. In this case, only the current (sub-) section
% is displayed in the header and not the full overview.
\mode<presentation>
{
  \usetheme[numbers, totalnumbers, compress]{Statmod}

  \setbeamercovered{transparent}
  % or whatever (possibly just delete it)
}

%\usepackage{pscyr}
\usepackage[T2A]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsmath,amssymb,amsthm,amscd,amsfonts}
\usepackage{mathdots}


%\usepackage{tikz}
% you only need this when using TikZ graphics

\newtheorem{theorem}{Теорема}
\newtheorem{example}{Пример}
\newtheorem{definition}{Определение}
\newtheorem{thnote}{Замечание}
\newtheorem{proposition}{Утверждение}
\newtheorem{solution}{Решение}

\DeclareMathOperator{\mathspan}{span}
\def\dist{\mathop{\mathrm{dist}}}

\input{letters}

\title[Аппроксимация рядами конечного ранга]{Аппроксимация временных рядов рядами конечного ранга}

\author[Звонарев Никита]{Звонарев Никита Константинович}
\institute[СПбГУ]{Санкт-Петербургский государственный университет \\
    Кафедра статистического моделирования \\
    \vspace{0.2cm}
    Научный руководитель: к.ф.-м.н., доц. Голяндина Н. Э. \\
    \vspace{0.2cm}
    Рецензент: к.ф.-м.н., доц. Коробейников А. И. \\
    \vspace{0.2cm}
}
\date{
    Санкт-Петербург\\
    2015г.
}

\subject{Beamer}
\setbeamertemplate{bibliography item}{[\theenumiv]}
% This is only inserted into the PDF information catalog. Can be left
% out.

% Delete this, if you do not want the table of contents to pop up at
% the beginning of each subsection:
% \AtBeginSubsection[]
% {
%   \begin{frame}<beamer>
%     \frametitle{Outline}
%     \tableofcontents[currentsection,currentsubsection]
%   \end{frame}
% }

\begin{document}

\begin{frame}
    \titlepage
\end{frame}


\section{Постановка задачи}
\begin{frame}
	\frametitle{Постановка задачи}
	Дан $\tsX = \tsS + \tsN$, $\tsX = (x_1, \ldots, x_N)$.
	
	Требуется построить оценку сигнала.

	$\tsN$ --- белый шум.

	$\tsS$ --- сигнал, управляемый \emph{линейной рекуррентной формулой}
	\begin{definition}
		Ряд, управляемый ЛРФ порядка~$r$: $\tsS = (s_1, \ldots, s_N), \quad s_n = \sum_{i = 1}^{r} a_i s_{n-i}, \, n = r + 1, \ldots, N, \, a_r \ne 0$.
	\end{definition}

	\vspace{0.5cm}
	Параметрический вид рядов, управляемых ЛРФ:
	\begin{equation*}
	s_n = \sum_i P_i(n) \exp(\alpha_i n) \cos(2 \pi \omega_i n + \psi_i).
	\end{equation*}
	
	Параметрический подход не работает из-за неустойчивости
\end{frame}

\begin{frame}
	\frametitle{Ряды конечного ранга}
	\vspace{-0.2cm}
	$\tsX = (x_1, \ldots, x_N)$ --- ряд.
	
	$1 < L < N$ --- \emph{длина окна}, $K = N - L + 1$.
	
	\emph{Траекторная матрица ряда} $\tsX$:
	
	\begin{equation*}
	\bfX = \calT(\tsX) = \begin{pmatrix}
	x_1 & x_2 & \ldots & x_K \\
	x_2 & x_3 & \ldots & x_{K + 1} \\
	\vdots & \vdots & \vdots & \vdots \\
	x_L & x_{L + 1} & \ldots & x_N
	\end{pmatrix}.
	\end{equation*}
	
	Заметим, что $\bfX$ --- ганкелева ($\bfX \in \calH$).
%	Заметим, что $\bfS$ --- ганкелева ($\bfS \in \calH$) и $\text{rank} \bfS = r$.
	
	\begin{definition}
	    Ряд $\tsS$ имеет L-ранг $r$ если $\operatorname{rank} \bfS = r$, где $\bfS = \calT(\tsS)$.  
	\end{definition}
	
	Ряд $\tsS$ управляется минимальной ЛРФ порядка $r$ $\Rightarrow$ $\tsS$ имеет L-ранг $r$.   
	
	$\sfX^r_N = \{\tsX : \tsX = (x_1, \ldots, x_N), \; \tsX \; \text{имеет L-ранг} \; \le r\}$
	
\end{frame}

\begin{frame}
	\frametitle{Эквивалентные задачи}
	\vspace{-0.2cm}
	$\tsX = (x_1, \ldots, x_N)$, $\bfX = \calT(\tsX)$. 
	
	Задача аппроксимации матрицы:
	\begin{equation} \label{matrixtask}
	\|\bfX - \bfY\|^2_\rmF \to \min_{\substack{\bfY \in \calM_r \cap \calH}},
	\end{equation}
	где $\calM_r$ --- множество матриц ранга $\le r$.
	
	$\hat \tsS = \calT^{-1}(\bfY)$ --- оценка $\tsS$.
	
	Задача аппроксимации рядов (эквивалентная \eqref{matrixtask}):
	\begin{equation*}
	\sum \limits_{i=1}^N q_i(x_i - y_i)^2 \to \min_{\tsY \in \calX_N^r},
	\end{equation*}
	где	\begin{equation*}
	q_i = \begin{cases}
	i & \text{для $i = 1, \ldots, L-1,$}\\
	L & \text{для $i = L, \ldots, K,$}\\
	N - i + 1 & \text{для $i = K + 1, \ldots, N,$}
	\end{cases} \qquad \text{---}
	\end{equation*}
	трапециевидные веса.
	
	\textcolor{blue}{Задача: как сделать веса $q_i$ равными?}
\end{frame}

%\begin{frame}
%	\frametitle{Постановка на матричном языке}
%	\begin{enumerate}
%		\item Временной ряд $\tsX = (x_1, \ldots, x_N)$.
%		\item $\bfX = \calT(\tsX)$, где $\calT$ --- биективное отображение на множество траекторных матриц:
%		\begin{equation*}
%		\bfX = \begin{pmatrix}
%		x_1 & x_2 & \cdots & x_K \\ 
%		x_2 & \iddots & \iddots & x_{K+1} \\ 
%		\vdots & \iddots & \vdots & \vdots \\ 
%		x_L & x_{L+1} & \cdots & x_N
%		\end{pmatrix} 
%		\end{equation*}
%		\item Найти $\bfY$: $||\bfX - \bfY||_? \to \min$, $\bfY \in \calH \cap \calM_r$, где $\calH$ --- множество ганкелевых матриц, $\calM_r$ --- матрицы ранга $\le r$.
%		\item $\tsY = \calT^{-1}(\bfY)$
%	\end{enumerate}
%\end{frame}

\begin{frame}
	\frametitle{План работы}
	\begin{description}
		\item[I часть] Теория
		\newcounter{itemcounter}
\begin{list}
	{\textcolor{blue}{\arabic{itemcounter}.}}
	{\usecounter{itemcounter}\leftmargin=-0.5em}

			\item Метод решения задачи аппроксимации в общем случае
			\item Применение теории к аппроксимации рядами конечного ранга
			\item Выбор норм, соответствие между весами для аппроксимации рядов и матриц
			\item Нахождение проекторов в выбранных нормах
		\end{list}
		\item[II часть] Алгоритмы и их особенности
		\item[III часть] Численные эксперименты	
		\setcounter{itemcounter}{0}
\begin{list}
	{\textcolor{blue}{\arabic{itemcounter}.}}
	{\usecounter{itemcounter}\leftmargin=-0.5em}

			\item Сравнение на модельном примере
			\item Реальный пример
		\end{list}		
	\end{description}
\end{frame}

\section{Теория}
\subsection{Метод решения в общем случае}
\begin{frame}
	\frametitle{Общая схема итераций}
	%$\bfY = (\Pi_\calH \circ \Pi_{\calM_r})^I (\bfX)$, $\Pi_\calH$ --- проектор на ганкелевы матрицы, $\Pi_{\calM_r}$ --- проектор на матрицы ранга $\le r$ по норме $||\cdot||$.
	
	$\sfX$ --- гильбертово пространство
	
	$\calH$ --- замкнутое (топологически) линейное подпространство. 
	
	$\calM$ --- замкнутое относительно умножения на константу подмножество, т.е. если $\bfz \in \calM$, то $\alpha \bfz \in \calM$ для любого $\alpha \in \sfR$.
	
	\vspace{0.6cm}
	Требуется спроектировать заданную точку $\bfx$ на $\calH \cap \calM$: 
	$\|\bfx - \bfy\| \to \min_\bfy$, где $\bfy \in \calH \cap \calM$
	
	\vspace{0.6cm}
	Метод переменных проекций (Alternating projections, AP): $\bfy_{k+1}=\Pi_\calH \Pi_\calM \bfy_{k}, \mbox{\ где\ } \bfy_{0}=x$, $\Pi_\calM$~---~проектор на $\calM$, $\Pi_\calH$ --- проектор на $\calH$.
\end{frame}

%\begin{frame}
%	\frametitle{``Теорема Пифагора''}
%	\begin{proposition}
%		Пусть $\sfX$ --- гильбертово пространство, $\calM \subset \sfX$ --- замкнутое относительно умножения на константу подпространство, $\Pi_\calM$ --- проектор на $\calM$. Тогда для любого $x \in \calX$ выполнено следующее равенство (``теорема Пифагора''):
%		\begin{equation*} 
%		\|x\|^2~=~\|x~-~\Pi_\calM x\|^2~+~\|\Pi_\calM x\|^2.
%		\end{equation*}
%	\end{proposition}
%\end{frame}

\begin{frame}
	\frametitle{Основная теорема}
	Один шаг алгоритма AP:
	$\bfy_{k+1}=\Pi_\calH \Pi_\calM \bfy_{k}, \mbox{\ где\ } \bfy_{0}=\bfx.$
	\begin{theorem}
			 Пусть $\sfX$ --- гильбертово пространство, $\calM \subset \sfX$ --- замкнутое относительно умножения на константу подпространство, множество $\calM$ и подпространство $\calH$ топологически замкнуты, $\Pi_\calM$~---~проектор на $\calM$. Тогда
			\begin{enumerate}
				\item $\|\bfy_k - \Pi_{\calM} \bfy_k\| \to 0$ при $k \to +\infty$, $\|\Pi_{\calM}\bfy_k - \bfy_{k+1}\| \to 0$ при $k \to +\infty$.
				\item Пусть $\calM \cap B_1$ является компактом, где $B_1 = \{\bfz: \|\bfz\| \le 1\}$~---~замкнутый единичный шар. Тогда существует сходящаяся подпоследовательность точек $\bfy_{i_1}, \bfy_{i_2}, \ldots$ такая, что ее предел $\bfy^*$  лежит в $\calM \cap \calH$.
			\end{enumerate}
	\end{theorem}
\end{frame}

%\begin{frame}
%	\frametitle{Замечания}
%	Применяем Теорему к нашему случаю: $\sfX = \sfR^{L \times K}$, $\calH$~---~ганкелевы матрицы, $\calM_r$ --- матрицы ранга $\le r$.
%	
%	\vspace{0.2cm}
%	
%	Соответствующий вид переменных проекций:
%	\begin{equation*}
%	\bfY_{k+1}=\Pi_\calH \Pi_{\calM_r} \bfY_{k}, \mbox{\ где\ } \bfY_{0}=\bfX \in \sfR^{L\times K}.
%	\end{equation*}
%	
%	\vspace{0.2cm}
%	
%	$\calM_r$ замкнуто при любой матричной норме.
%	
%	\vspace{0.2cm}
%	
%	В дальнейшем, мы будем рассматривать нормы, порожденные следующими взвешенными фробениусовскими скалярными произведениями: 
%	\begin{equation*}
%	\langle\bfY, \bfZ\rangle_M = \sum_{l = 1}^L \sum_{k = 1}^K m_{l, k} y_{l, k} z_{l, k}, \quad \text{где все} \quad m_{l,k} > 0.
%	\end{equation*}
%	
%\end{frame}

\subsection{Применение теории к аппроксимации рядами}
\begin{frame}
	\frametitle{Обратно к задаче}
	Ряды: $\sum \limits_{i=1}^N q_i(x_i - y_i)^2 \to \min,$ $\tsY \in \calX_N^r$, заданы $q_i > 0$.
	
	Матрицы: $\bfY$: $\|\bfX - \bfY\|_? \to \min$, $\bfY \in \calH \cap \calM_r$. Так как $q_i$ задаются, то требуется другая (не фробениусовская)  норма.
	
	\vspace{0.3cm}
	Применяем алгоритм к нашему случаю, и получаем решение. Переменные проекции: 
	\begin{equation*}
	\bfY_R = (\Pi_\calH \circ \Pi_{\calM_r})^R (\bfX),
	\end{equation*}
	$\Pi_\calH$ --- проектор на ганкелевы матрицы, $\Pi_{\calM_r}$ --- проектор на матрицы ранга $\le r$, $R$ --- число итераций.
	
	Теорема применима к задаче $\Rightarrow$ существование сходящейся к нужному множеству подпоследовательности.
\end{frame}

\subsection{Выбор норм, соответствие между весами}
\begin{frame}
	\frametitle{Варианты норм}
	Ряды:
	$\|\tsX\|_q^2 = \sum_{i = 1}^N q_i x_i^2$, все $q_i \ge 0$
	
	\vspace{0.4cm}
	Матрицы:
		\begin{enumerate}
			\item $\|\bfX\|_{1, M}^2 = \sum_{l = 1}^L \sum_{k = 1}^K m_{l, k} (x_{l, k})^2$, все $m_{l, k} \ge 0$
			\item Частный случай предыдущего пункта: $m_{l, k} = 1$.
			\item $\|\bfX\|_{2, \bfC}^2 = \text{tr}(\bfX \bfC \bfX^\rmT)$, $\bfC$ --- симметричная, неотрицательно определенная матрица порядка $K \times K$ (+ диагональная в нашем случае)
		\end{enumerate}
		
		\vspace{0.4cm}
		Проблемы:
		\begin{enumerate}
			\item Как подобрать $m_{i, j}$, соответствующие $q_i$?
			\item Как вычислить $\Pi_\calH$, $\Pi_{\calM_r}$ по нужной норме?
		\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Эквивалентность скалярных произведений и норм}
	\begin{enumerate}
		\item $\langle \tsX, \tsY \rangle_q = \sum_{i=1}^N q_i x_i  y_i$
		\item $\langle\bfX, \bfY \rangle_{1, M} = \sum_{l = 1}^L \sum_{k = 1}^K m_{l, k} x_{l, k} y_{l, k}$
		\item $\langle\bfX, \bfY\rangle_{2, \bfC} = \text{tr}(\bfX \bfC \bfY^\rmT)$.
	\end{enumerate}
	\begin{proposition}
		\small
	    \begin{enumerate}
		\item Пусть $\bfX = \calT(\tsX)$,  $\bfY = \calT(\tsY)$. Тогда $\langle\tsX,\tsY\rangle_q= \langle\bfX,\bfY\rangle_{1, M}$ тогда и только тогда, когда
		\begin{equation*}
		q_i = \sum_{\substack{1 \le l \le L \\ 1 \le k \le K \\ l+k-1=i}} m_{l,k}.
		\end{equation*}
		
		\item Для диагональной матрицы $\bfC$, $\langle \bfX,\bfY \rangle_{1, M}= \langle \bfX,\bfY \rangle_{2, \bfC}$ тогда и только тогда, когда
		\begin{equation*}
		m_{l,k}=c_{k,k}.
		\end{equation*}
	    \end{enumerate}
	\end{proposition}
	
\end{frame}

\subsection{Нахождение проекторов в выбранных нормах}
\begin{frame}
	\frametitle{Проектор $\Pi_{\calM_r}$}
	Варианты:
	\begin{enumerate}
		\item $\|\bfX\|_{1, M}$, все $m_{l, k} = 1$: через стандартное SVD-разложение. $\Pi_{\calM_r}(\bfX) = \bfU \Sigma_r \bfV^\rmT$, где $\bfX = \bfU \Sigma \bfV^\rmT$.
		
		\vspace{0.2cm}
		\item $\|\bfX\|_{2, \bfC}$: косоугольное SVD-разложение. Сводится к п. 1
		
		\vspace{0.2cm}
		\item $\|\bfX\|_{1, M}$, общий случай: EM-подобный алгоритм.

	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Проектор $\Pi_{\calH}$}
	Общий случай (взвешенное диагональное усреднение):
	\begin{equation*}
		\bfX = \Pi_{\calH}(\bfY), \quad x_{l,k} = \frac{\sum_{i,j:\, i+j=l+k} m_{i, j} y_{i,j}}{\sum_{i,j:\, i+j=l+k} m_{i,j}}.
	\end{equation*}
		
	Варианты:
	\begin{enumerate}
		\item $\|\bfX\|_{1, M}$, $m_{l,k}$ на побочных диагоналях равны, в частности $m_{l, k} = 1$: диагональное усреднение.
		\begin{equation*}
		\bfX = \Pi_{\calH}(\bfY), \quad x_{l,k} = \sum_{i + j = l + k} y_{i, j} / w_{l + k - 1}.
		\end{equation*}
		\item $\|\bfX\|_{2, \bfC}$, $\bfC$ --- диагональная: взвешенное диагональное усреднение с весами $m_{i,j} = c_{i, i}$, где $\bfC = (c_{i, j})$.
		
	\end{enumerate}
\end{frame}

\subsection{Алгоритмы и их особенности}
\begin{frame}
	\frametitle{Варианты алгоритма Cadzow} 
	$\|\bfX\|_{2, \bfC}^2 = \text{tr}(\bfX \bfC \bfX^\rmT)$
	\begin{itemize}
		\item $\bfC = \bfI_K$ --- базовый алгоритм \textcolor{blue}{Cadzow} (Cadzow, 1988) ($\Pi_{\calM_r}$ --- используя обычное SVD, $\Pi_\calH$ --- диаг. усреднение).
		\item $\bfC = \text{diag}(1, \alpha, \alpha, \ldots, \alpha, 1, \alpha, \ldots, 1)$,
		где единицы стоят на $1$, $L + 1$, $2L + 1$, \ldots , $K$ месте, $0 \le \alpha \le 1$. \\ \textcolor{blue}{Cadzow($\alpha$)} (Zhigljavsky, 2015)
		
		$\Pi_{\calM_r}$ --- косоугольное SVD, $\Pi_\calH$ --- взвешенное диагональное усреднение.
	\end{itemize}
	
	\vspace{0.3cm}
	$\|\bfX\|^2_{1, M} =  \sum_{l = 1}^L \sum_{k = 1}^K m_{l, k}$
	\begin{itemize}
		\item $\|\bfX\|_{1, M}$, $m_{l, k}$ такие, что $q_i = 1$ --- \textcolor{blue}{Weighted Cadzow} ($\Pi_{\calM_r}$ --- EM, $\Pi_\calH$ --- диаг. усреднение). Для него все $q_i$ = 1.
		\item \textcolor{blue}{Extended Cadzow} (использует искусственное продолжение ряда в обе стороны)
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Различные особенности}
	 $\bfC = \text{diag}(1, \alpha, \alpha, \ldots, \alpha, 1, \alpha, \ldots, 1)$ (Cadzow($\alpha$)).
	\begin{theorem}
		Эквивалентные веса ряда в алгоритме Cadzow($\alpha$):
		\begin{equation*}
		q_i = \begin{cases}
		1 + (i - 1) \alpha & \text{для $i = 1, \ldots, L-1,$}\\
		1 + (L - 1) \alpha & \text{для $i = L, \ldots, K-1,$}\\
		1 + (N - i) \alpha & \text{для $i = K, \ldots, N.$}
		\end{cases}
	    \end{equation*}
	\end{theorem}
	
	Достаточно взять $\alpha = 0$, чтобы получить равномерные веса? \textcolor{red}{Нет!}
	\begin{itemize}
		\item  $\alpha = 0$~--- другая задача
		\item $\alpha \approx 0$, $\alpha > 0$: медленно сходится, проблемы со слабой разделимостью, требуется, чтобы $N \vdots L$.
		\item $\alpha = 1$~--- базовый алгоритм Cadzow
	\end{itemize}

\end{frame}

%\begin{frame}
%	\frametitle{Алгоритм Extended Cadzow}
%	\begin{equation*}
%	\calX = \begin{pmatrix}
%	&  &  & x_1 & x_2 & \cdots & x_K & x_{K+1} & \cdots & x_N \\ 
%	&  & \iddots & x_2 & x_3 & \iddots & x_{K+1} & \iddots & \iddots &  \\ 
%	& x_1 & \iddots & \iddots & \iddots & \iddots & \iddots & x_N &  &  \\ 
%	x_1 & x_2 & \cdots & x_L & x_{L+1} & \cdots & x_N &  &  & 
%	\end{pmatrix}.
%	\end{equation*}
%	\begin{enumerate}
%		\item $q_i = 1$, $i = 1, \ldots, N$, но задача несколько иная
%		\item $\tilde \calT$ : $\tilde \calT(\tsX) = \calX$ --- биекция между рядами и матрицами с пропусками.
%		\item Проектор на множество матриц неполного ранга $\Pi_{\widetilde \calM_r}$ (EM-алгоритм).
%		\item Проектор на множество траекторных матриц с пропусками $\Pi_\gX$ (диагональное усреднение).
%		\item Сам алгоритм: $\tsY = \tilde \calT^{-1}((\Pi_\gX \circ \Pi_{\widetilde \calM_r})^I (\tilde \calT(\tsX)))$.
%	\end{enumerate}
%\end{frame}

%\begin{frame}
%	\frametitle{Различные проблемы}
%	\begin{itemize}
%		\item Базовый алгоритм Cadzow --- имеет $q_i$, далекие от оптимальных
%		\item 
%		\item Cadzow($\alpha$) с косоугольным SVD: 
%	\end{itemize}
%\end{frame}

%\section{Слабая разделимость}
%\begin{frame} \small
%	\frametitle{Слабая разделимость в косоугольном случае}
% $\bfC \in \sfR^{K \times K}$ --- симметричная неотрицательно определенная, $\tsX_1$ и $\tsX_2$~--- два временных ряда длины $N$, $\bfX^1$, $\bfX^2$ --- их траекторные матрицы. Определим \emph{коэффициент корреляции $i$-го и $j$-го столбца}:
%\begin{equation*}
%\rho^c_{i,j} = \frac{(X^1_i, X^2_j)}{\|X^1_i\| \|X^2_j\|},
%\end{equation*}
%где $X^k_i$ --- $i$-й столбец матрицы $\bfX^k$, $k = 1, 2$. 
%
%\emph{Коэффициент корреляции $i$-й и $j$-й строчки}:
%\begin{equation*}
%\rho^r_{i,j} = \frac{(X^{1,i}, X^{2,j})_\bfC}{\|X^{1,i}\|_\bfC \|X^{2,j}\|_\bfC},
%\end{equation*}
%где $X^{k,i}$ --- $i$-я строка матрицы $\bfX^k$, $k = 1, 2$, а $(\cdot, \cdot)_\bfC$ --- косоугольное скалярное произведение в $\sfR^K$, порожденное матрицей $\bfC$: $(X, Y)_\bfC = X \bfC Y^\sfT$ (здесь $X$, $Y$ --- вектор-строчки), $\| \cdot \|_\bfC$ --- соответствующая норма.
%\end{frame}

%\begin{frame}
%	\frametitle{Слабая разделимость гармоники и константы}
%	\begin{definition}
%		Скажем, что ряды $\tsX_1$ и $\tsX_2$ \emph{слабо $\varepsilon$-разделимы} если
%		\begin{equation*}
%			\rho = \max\Big(\max_{1 \le i,j \le K}|\rho^c_{i,j}|, \max_{1 \le i,j \le L}|\rho^r_{i,j}|\Big) < \varepsilon.
%		\end{equation*}
%	\end{definition}
%	Интересует порядок $\varepsilon$ при $N \to \infty$, если брать первые $N$ точек бесконечного ряда.
	
%	Будем рассматривать $\tsX_1^\infty = (\cos(2 \pi \omega k), k = 1, 2, \ldots)$ и $\tsX_2^\infty = (c, c, \ldots)$ при $L, K \to \infty$, где $N = L + K - 1$.
	
%	\vspace{0.3cm}
%	Известный результат: когда $\bfC$ --- единичная матрица, то $\varepsilon$ имеет порядок $1/\min(L,K)$.
%\end{frame}

%\begin{frame}
%	\frametitle{Слабая разделимость: новые результаты}
%\begin{proposition}
%	Пусть $\tsX_1^\infty = (\cos(2 \pi \omega k), k = 1, 2, \ldots)$, где $0<\omega <0.5$ --- синусоида, $\tsX_2^\infty = (c, c, \ldots)$ --- константа,  $L,K \to \infty$ так, что $h = h_L = N/L$, где $N=L+K-1$, целое, и $\bfC=\bfC(\alpha)$ диагональная с диагональными элементами (алгоритм Cadzow($\alpha$)):
%	\begin{equation*}
%	c_k = \begin{cases}
%	1, & \text{если} \quad k = jL+1 \quad \text{для некоторых} \ j = 0, \ldots, h-1,\\
%	\alpha, & \text{в противном случае},
%	\end{cases}
%	\end{equation*}
%	где $0 \le \alpha \le 1$. Тогда $\rho$ имеет порядок $\max\left(\frac{1}{L}, \frac{(1-\alpha)C_{L,K}+\alpha}{(1-\alpha)N/L+\alpha K}\right)$, где порядок $C_{L,K}$
%	может меняться от $O(1)$ to $O(N/L)$ в зависимости от того, как $L$ и $K$ стремятся к бесконечности.
%	\end{proposition}
%    \small Если $\exists \delta,$ $0 < \delta < 0.5$: $L \omega \in [k + \delta, \, k + 1 - \delta]$ для всех целых $k$, всех $L$ из последовательности, то $C_{L, K} = O(1)$.
%\end{frame}

%\begin{frame}
%	\frametitle{Слабая разделимость: порядок}
%	\begin{itemize}
%		\item Оптимальный выбор для $L$ это $L \approx \frac{\alpha(N + 1) + \sqrt{\alpha^2(N+1)^2 + 4N(1  - \alpha^2)}}{2(1 + \alpha)}$
%		\item В этом случае порядок разделимости $\rho = O \left(\frac{1}{\alpha N + \sqrt{N(1 - \alpha ^ 2)}} \right)$
%		\item Для фиксированного $\alpha$ порядок разделимости остаётся равным $1/N$ (и $O(N/L) = O(1)$, т.к. $N/L$ ограничено)
%		\item Если рассматривать $\alpha(N) = O(N^{-\beta})$, то порядок становится равным $O(N^{\beta - 1})$ для $0 \le \beta \le 0.5$, и $O(1/\sqrt{N})$ для $\beta > 0.5$.
%	\end{itemize}
%\end{frame}

 
\section{Численные эксперименты}
\subsection{Сравнение на модельном примере}
\begin{frame}
	\frametitle{Сравнение (одна итерация)}
	Задача оценки сигнала: $N = 40$, $L = 20$, $r = 2$, $\tsX = (x_{1}, \ldots, x_N),$  $x_k = 5\sin{\frac{2 k \pi}{6}} + \varepsilon_k$; $\varepsilon_k$, $k = 1, \ldots N$, --- гауссовский белый шум, $\tsE \varepsilon_k = 0$, $\tsD \varepsilon_k = 1$, 1000 реализаций.

	\vspace{-0.3cm}
	\begin{center}
		\includegraphics*[width = 9cm]{s1_it1.pdf}
	\end{center}
\end{frame}

\begin{frame}
	\frametitle{Сравнение (100 итераций)}
	Задача оценки сигнала: $N = 40$, $L = 20$, $r = 2$, $\tsX = (x_{1}, \ldots, x_N),$  $x_k = 5\sin{\frac{2 k \pi}{6}} + \varepsilon_k$; $\varepsilon_k$, $k = 1, \ldots N$, --- гауссовский белый шум, $\tsE \varepsilon_k = 0$, $\tsD \varepsilon_k = 1$, 1000 реализаций.
	\vspace{-0.3cm}
	
	\begin{center}
		\includegraphics*[width = 9cm]{s1_it100.pdf}
	\end{center}
\end{frame}

\begin{frame}
	\frametitle{Сравнение (зависимость RMSE от числа итераций)}
	Задача оценки сигнала: $N = 40$, $L = 20$, $r = 2$, $\tsX = (x_{1}, \ldots, x_N),$  $x_k = 5\sin{\frac{2 k \pi}{6}} + \varepsilon_k$; $\varepsilon_k$, $k = 1, \ldots N$, --- гауссовский белый шум, $\tsE \varepsilon_k = 0$, $\tsD \varepsilon_k = 1$, 1000 реализаций.
	
	\vspace{-1cm}
	\begin{center}
		\includegraphics*[width = 10cm]{cadzowspeed_3.pdf}
	\end{center}
\end{frame}

%\begin{frame}
%	\frametitle{Пример №4: среднее количество итераций и RMSE}
%	Задача оценки сигнала: $N = 40$, $L = 20$, $r = 2$, $\tsX = (x_{1}, \ldots, x_N),$  $x_k = 5\sin{\frac{2 k \pi}{6}} + \varepsilon_k$.
%	
%	Критерий остановки: $\frac{\|\calT^{-1}(\bfY_k) - \calT^{-1}(\bfY_{k + 1})\|^2}{N} < 10^{-8}$
%	\vspace{-0.4cm}
%	\begin{center}
%		\includegraphics*[width = 9cm]{2axis.pdf} 
%	\end{center}
%\end{frame}

%\begin{frame}
%	\frametitle{Пример №4.5: $\sigma = 3$}
%	Задача оценки сигнала: $N = 40$, $L = 20$, $r = 2$, $\tsX = (x_{1}, \ldots, x_N),$  $x_k = 5\sin{\frac{2 k \pi}{6}} + 3 \varepsilon_k$.
	
%	Критерий остановки: $\frac{\|\calT^{-1}(\bfY_k) - \calT^{-1}(\bfY_{k + 1})\|^2}{N} < 10^{-8}$
%	\vspace{-0.4cm}
%	\begin{center}
%		\includegraphics*[width = 9cm]{2axis-3.pdf}
%	\end{center}
%\end{frame}

\subsection{Реальный пример}
\begin{frame}
	\frametitle{Реальный пример}
    Ряд `Fortified wine', первые 168 значений.
    
    Схема выбора параметра $\alpha$ для применения метода Cadzow($\alpha$):
    \begin{itemize}
    	\item Построена параметрическая модель ``похожего'' ряда с помощью SSA + ESPRIT
    	\item С помощью моделирования метода Cadzow($\alpha$) получено качество оценки модельного сигнала и точность аппроксимации ряда
    	\item Найден промежуток значений $\alpha$, на котором улучшение точности аппроксимации даёт улучшение RMSE оценки сигнала
    	\item Метод применён к исходному ряду с параметром $\alpha$, соответствующим наибольшей точности
    \end{itemize}
\end{frame}

%\begin{frame}
%	\frametitle{Пример из жизни: результаты моделирования}
%\begin{table}
%	\caption{Сравнение методов по оценке сигнала, аппроксимации ряда `Fortifide wine' и его промоделированных копий.}
%	\label{tab:rltable}
%	
%	\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}ccccc}
%		\hline
%		Метод: & $\tsS$ & $\tsX$ & $\tsX^*$ \\
%		\hline
%		Cadzow, $\alpha = 1$ & 127.71 & 263.20 & 283.58 \\
%		\hline
%		Cadzow, $\alpha = 0.8$ & 127.18 & 262.98 & 283.25 \\
%		\hline
%		Cadzow, $\alpha = 0.6$ & 126.42 & 262.63 & 282.72 \\
%		\hline
%		Cadzow, $\alpha = 0.4$ & 125.39 & 262.06 & 281.77 \\
%		\hline
%		Cadzow, $\alpha = 0.2$ & 124.10 & 260.94 & 279.55 \\
%		\hline
%		Cadzow, $\alpha = 0.1$ & 125.09 & 260.52 & 276.70 \\
%		\hline
%		Cadzow, $\alpha = 0.05$ & 129.44 & 261.47 & 274.00 \\
%		\hline
%	\end{tabular*}
%\end{table}
%\end{frame}

\begin{frame}
	\frametitle{Реальный пример: наилучшее приближение}
	Получено алгоритмом Cadzow($0.2$). Пунктирная линия --- исходный ряд, сплошная линия --- аппроксимация рядом конечного ранга.
	\vspace{-0.2cm}
	\begin{center}
		\includegraphics*[width = 9cm]{rlimage.pdf}
	\end{center}
\end{frame}

%\begin{frame}
%	\frametitle{Пример № последний: красный и белый шум, $\sigma = 2$}
%	$N = 40$, $L = 20$, $r = 2$, $\tsX = (x_{1}, \ldots, x_N),$  $x_k = 5\sin{\frac{2 k \pi}{6}} + 2 \varepsilon_k$.
%	$\tsY = (y_{1}, \ldots, y_N),$  $y_k = 5\sin{\frac{2 k \pi}{6}} + 2 \gamma_k$, $\gamma_k = \varphi \gamma_{k - 1} + \sqrt{1 - \varphi^2} \epsilon_k$, $\varphi = 0.8$.
%	\vspace{-0.4cm}
%	\begin{center}
%		\includegraphics*[width = 9cm]{2axis-2.pdf} 
%	\end{center}
%\end{frame}

\section{Итоги}

%\begin{frame}
%  \frametitle{Выводы}
%  Рассмотрен широкий класс алгоритмов, проведено сравнение на модельном примере:
%  \begin{itemize}
%  \item Доказана сходимость по подпоследовательностям для всех алгоритмов
%  \item Единичные веса достигаются только на алгоритмах с вложенными итерациями (Extended, Weighted Cadzow), которые являются медленными.
%  \item Алгоритмы с более близкими к единичным весами дают лучшую аппроксимацию в пределе, но медленее сходятся и имеют проблемы с разделимостью:
%  
%  Cadzow($\alpha$): малое $L$, $\alpha$ $\Rightarrow$ плохая разделимость
%  \item Лучший метод среди всех -- Extended Cadzow. Среди методов без внутренних итераций на одной лучше всего работает Cadzow($1$) и Hat-Cadzow, в пределе --- Cadzow($0.1$)
%  \end{itemize}

%\end{frame}

\begin{frame}
	\frametitle{Итоги}
	\begin{itemize}
		\item Рассмотрен широкий класс итерационных алгоритмов решения задачи 
		%(повторить для рядов с весами $q_i$) 
		для оценивания сигнала $\tsS$  в модели $\tsX = \tsS + \tsN$
		\item Доказано существование сходящейся подпоследовательности для всех алгоритмов
		\item Установлено соотношение между разделимостью, скоростью сходимости и точностью в пределе на численных примерах
		\item Проведено численное сравнение на модельном и реальном примере
		\item Получена скорость разделимости для одного примера в алгоритме Cadzow($\alpha$), рекомендации к быстрой реализации алгоритмов (в приложении)
	\end{itemize}
	
\end{frame}

\bibliographystyle{plain}

\end{document}