
\documentclass[12pt,a4paper]{article}
\usepackage[a4paper,
mag=1000, includefoot,
left=3cm, right=1.5cm, top=2cm, bottom=2cm, headsep=1cm, footskip=1cm]{geometry}
\usepackage{mathtext}
\usepackage{cmap}
\usepackage[utf8x]{inputenc}
\usepackage[russian]{babel}
\usepackage[T2A]{fontenc}
\usepackage{amsmath,amssymb,amsthm,amscd,amsfonts}
\usepackage{euscript}
\usepackage{relsize}
\usepackage{mathdots}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{caption2}
\usepackage{indentfirst}
\usepackage{fancyhdr}
\usepackage{sectsty}
\usepackage{titlesec}
\usepackage{mathtext}%русские буквы в формулах

\usepackage[colorlinks, urlcolor=blue, pdfborder={0 0 0 [0 0]}]{hyperref}

\hyphenation{Struc-tu-red}
\hyphenation{Ran-do-mized}
\hyphenation{Ma-xi-mi-za-tion}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\tr}{tr}
\providecommand*{\BibDash}{}

\def\rank{\mathop{\mathrm{rank}}}
\newtheorem{corollary}{Следствие}
\newtheorem{proposition}{Предложение}
\newtheorem{algorithm}{Алгоритм}
\newtheorem{theorem}{Теорема}
\newtheorem{lemma}{Лемма}

\usepackage{euscript}
\input{newcommands}
\input{letters}

%\sectionfont{\centering}

%\subsectionfont{\centering}
%\subsubsectionfont{\normalsize}
%\setcounter{page}{1}


\author{Звонарев Никита}
\title{Односторонние веса ряда}
\begin{document}
\maketitle
\section{Постановка задачи нахождения весов}
\subsection{Общие соображения}
В этом разделе рассмотрим различные способы нахождения матричных весов $c_i$, $i = 1, \ldots, K$ с целью получения приближённо равных весов ряда $q_i$, $i = 1, \ldots, N$. Теорема \footnote{ссылка на соотношение между весами} даёт необходимые и достаточные условия существования точных единичных весов ряда. Однако, мы тут же сталкиваемся с двумя проблемами. Во-первых, $N$ должно быть кратно $L$. Чаще всего $L$ стоит брать приближённо равным $N/2$, но $N$ может быть как нечётным, так и вовсе простым числом! Естественно, как резкое ограничение на возможные длины окна $L$, так и возможное обрезание ряда $\tsX$ до кратной $L$ длины крайне нежелательны. Во-вторых, полученные в теореме (?) веса $c_i$ содержат нули, что неприменимо, согласно \footnote{замечание про кривой Cadzow(0)}. В алгоритме Cadzow($\alpha$) \footnote{ссылка на статью} предложено заменять нули на $\alpha$. Согласно \footnote{ссылка на статью}, параметр $\alpha$ напрямую влияет на скорость сходимости метода Cadzow($\alpha$): меньшие $\alpha$ замедляют сходимость метода.

Введём следующие ограничения на допустимые веса $c_i$: во-первых, все $c_i > 0$. Во-вторых, по аналогии с алгоритмом Cadzow($\alpha$), введём параметр $0 \le \alpha \le 1$. Как будет выяснено далее в Разделе \footnote{ссылка}, на скорость сходимости алгоритма Oblique Cadzow влияет число обусловленности (condition number) матрицы $\bfC = \text{diag}(c_1, \ldots, c_K)$, задающей косоугольное произведение в пространстве строк: чем больше $\text{Сond}(\bfC)$, тем медленнее сходится метод Oblique Cadzow. Поэтому рассмотрим следующее ограничение: 
\begin{equation} \label{eq:ratiocond}
\frac{\min_i c_i}{\max_i c_i} \ge \alpha,
\end{equation}
что эквивалентно тому, что $\text{Сond}(\bfC) \le 1/\alpha$.

Именно из-за вышеназванной особенности рассматривается такое на первый взгляд странное ограничение (вместо, например, $c_i >= \alpha > 0$, $i = 1, \ldots, K$).

\subsection{Общая постановка задачи аппроксимации весов}
Для удобства перепишем уравнение \footnote{ссылка на уравнение, связывающее $c_i$ и $q_i$} в матричном виде. Для этого рассмотрим матрицу $\bfT$ порядка $N \times K$, имеющую следующий вид:
\begin{equation} \label{eq:tmatrix}
\bfT = (t_{i, j}), \quad t_{i, j} = \begin{cases}
1, & \text{для} \; i = j, \ldots, j + L - 1, \\
0, & \text{в противном случае}.
\end{cases}
\end{equation}
Таким образом, вектор весов ряда $Q = (q_1, \ldots, q_N)^\rmT$ может быть выражен через вектор матричных весов $C = (c_1, \ldots, c_K)^\rmT$ как $Q = \bfT C$. Заметим, что матрица $\bfT$ является матрицей полного ранга.

В общем виде задача формулируется следующим образом:
\begin{multline} \label{eq:commonw}
\|\bfT C - I_N\|_\cdot \to \min_{c_i, i = 1, \ldots, K} \quad \text{при условиях} \;
c_i > 0, \; i = 1, \ldots, K, \; 
\frac{\min_i c_i}{\max_i c_i} \ge \alpha,
\end{multline}
где $I_N = (1, \ldots, 1)^\rmT$ --- требуемые веса ряда (вектор из $N$ единиц), $0 \le \alpha \le 1$ --- параметр, регулирующий скорость сходимости алгоритма Oblique Cadzow, $\|\cdot\|_\cdot$ --- норма в $\sfR^N$. Рассмотрим следующие стандартные нормы:
\begin{enumerate}
	\item $\|X\|_\cdot = \|X\|_\infty = \max_i |x_i|$,
	\item $\|X\|_\cdot = \|X\|_1 = \sum_i |x_i|$ --- норма, порождающая манхеттенскую метрику,
	\item $\|X\|_\cdot = \|X\|_2 = \sqrt{\sum_i x_i^2}$ --- обычная евклидова норма.
\end{enumerate}
Рассмотрим каждый случай по отдельности.

\subsection{Случай нормы $\|X\|_\infty$}
Покажем, что данная задача сводится к задаче линейного программирования с линейными ограничениями с помощью добавления вспомогательных переменных.

Введём $c_\text{max}$ --- дополнительную переменную, хранящую максимальный вес, и перейдём к новым переменным $\hat c_i = c_\text{max} - c_i$, $i = 1, \ldots, K$ --- разница между максимальным среди всех и текущим весом, при этом $c_\text{max} \ge 0$, $\hat c_i \ge 0$. Между векторами $C = (c_1, \ldots, c_K)^\rmT$ и $\widehat C = (\hat c_1, \ldots, \hat c_K, c_\text{max})^\rmT$ существует простое линейное соответствие: $C = \bfH \widehat C$, где $\bfH \in \sfR^{K \times (K+1)}$ --- матрица следующего вида:
\begin{equation} \label{eq:hmatrix}
\bfH = \left(
\begin{array}{cccc}
-1 &  &  & 1 \\ 
& \ddots &  & \vdots \\ 
&  & -1 & 1
\end{array} 
\right).
\end{equation}
Условие \eqref{eq:ratiocond}, устанавливающее границу снизу для весов, в новых обозначениях записывается как $(1 - \alpha) c_\text{max} - \hat c_i \ge 0$, $i = 1, \ldots, K$.

Рассмотрим $\omega \in \sfR$ --- ещё один дополнительный параметр, который хранит значение целевой функции. Заметим, что при любых дополнительных условиях, любой матрице $\bfA \in \sfR^{N \times K}$, любого $\widetilde Y \in \sfR_N$, $\widetilde Y = (\tilde y_1, \ldots, \tilde y_N)^\rmT$, следующие задачи эквивалентны: 
\begin{equation*}
\|\bfA X - \widetilde Y \|_\infty \to \min_{X \in \sfR_K}
\end{equation*}
и 
\begin{gather*}
\omega \to \min_{X, \omega} \quad \text{при условиях} \\ \bfA X = Y = (y_1, \ldots, y_N)^\rmT, \quad y_i - \tilde y_i \le \omega, \quad y_i - \tilde y_i \ge -\omega, \quad i = 1, \ldots, N. 
\end{gather*}

Таким образом, в терминах линейного программирования задача \eqref{eq:commonw} в случае нормы $\|X\|_\infty$ переписывается следующим образом:
\begin{gather*}
\omega \to \min_{c_\text{max}, \, \hat c_1, \ldots, \hat c_K, \, \omega} \quad \text{при условиях} \\ \bfT \bfH \widehat C = Q = (q_1, \ldots, q_N)^\rmT, \quad q_i - 1 \le \omega, \quad q_i - 1 \ge -\omega, \quad i = 1, \ldots, N, \\
c_\text{max} \ge 0, \quad \hat c_j \ge 0, \quad (1 - \alpha) c_\text{max} - \hat c_j \ge 0, \quad j = 1, \ldots, K.
\end{gather*}

\subsection{Случай нормы $\|X\|_1$}
Аналогично предыдущему случаю, задача \eqref{eq:commonw} может быть записана в терминах линейного программирования.

Для этого заметим следующее: если ввести $2N$ дополнительных переменных \\ $\kappa_1, \ldots, \kappa_N$, $\theta_1, \ldots, \theta_N \in \sfR$, то при любых дополнительных условиях, любой матрице $\bfA \in \sfR^{N \times K}$, любого $\widetilde Y \in \sfR_N$, $\widetilde Y = (\tilde y_1, \ldots, \tilde y_N)^\rmT$, следующие задачи эквивалентны: 
\begin{equation*}
\|\bfA X - \widetilde Y \|_1 \to \min_{X \in \sfR^K}
\end{equation*}
и 
\begin{gather*}
\sum_{i = 1}^N (\kappa_i + \theta_i) \to \min_{X, \, \kappa_1, \ldots, \kappa_N, \, \theta_1, \ldots, \theta_N} \quad \text{при условиях} \\ \bfA X = Y = (y_1, \ldots, y_N)^\rmT, \quad y_i - \tilde y_i = \kappa_i - \theta_i, \quad \kappa_i \ge 0, \quad \theta_i \ge 0, \quad i = 1, \ldots, N. 
\end{gather*}

В итоге, задача \eqref{eq:commonw} в терминах линейного программирования в случае нормы $\|X\|_1$ переписывается следующим образом:
\begin{gather*}
\sum_{i = 1}^N (\kappa_i + \theta_i) \to \min_{c_\text{max}, \, \hat c_1, \ldots, \hat c_K, \, \kappa_1, \ldots, \kappa_N, \, \theta_1, \ldots, \theta_N} \quad \text{при условиях} \\ \bfT \bfH \widehat C = Q = (q_1, \ldots, q_N)^\rmT,  \quad q_i - 1 = \kappa_i - \theta_i, \quad \kappa_i \ge 0, \quad \theta_i \ge 0, \quad i = 1, \ldots, N, \\
c_\text{max} \ge 0, \quad \hat c_j \ge 0, \quad (1 - \alpha) c_\text{max} - \hat c_j \ge 0, \quad j = 1, \ldots, K.
\end{gather*}

\subsection{Случай нормы $\|X\|_2$: неотрицательно определённая задача}
В случае евклидовой нормы для записи задачи \eqref{eq:commonw} не требуется вводить дополнительные переменные. После исключения константы, получаем следующую задачу квадратичного программирования с линейными ограничениями:
\begin{gather}\label{eq:nonnegatqw}
f(\widehat C) = \frac{1}{2} \widehat C^\rmT  \bfH^\rmT \bfT^\rmT \bfT \bfH \widehat C - I_N^\rmT \bfT \bfH  \widehat C \to \min_{c_\text{max}, \, \hat c_1, \ldots, \hat c_K} \quad \text{при условиях} \\
\label{eq:nonnegatqw_cond}
c_\text{max} \ge 0, \quad \hat c_j \ge 0, \quad (1 - \alpha) c_\text{max} - \hat c_j \ge 0, \quad j = 1, \ldots, K,
\end{gather}
где $I_N$ --- вектор-столбец, состоящий из $N$ единиц. 

Существует следующее простейшее утверждение, которое устанавливает вид матрицы $\bfT^\rmT \bfT$ и вектора $I_N \bfT$:
\begin{proposition}\label{th:TtTandInT} Справедливо следующее:
	
	\begin{enumerate}
		\item $\bfS = \bfT^\rmT \bfT$ --- положительно определённая матрица размера $K \times K$, которая равна:
		\begin{equation*}
		\bfT^\rmT \bfT = \bfS = (s_{i,j}), \quad s_{i,j} = \begin{cases}
		L - |i - j|, & |i - j| \le L, \\
		0, & \text{в противном случае}.
		\end{cases}
		\end{equation*}
		\item Вектор $B = \bfT^\rmT I_N  \in \sfR^K$, $B = (L, \ldots, L)^\rmT$. 
	\end{enumerate}
\end{proposition}

Пользуясь тем, что $\bfH$ --- простое линейное отображение, нетрудно получить явный вид матрицы $\bfH^\rmT \bfT^\rmT \bfT \bfH = \bfH^\rmT \bfS \bfH$ и $I_N^\rmT \bfT \bfH = B^\rmT \bfH$. Проблема состоит в том, что неотрицательно определённая матрица $\bfH^\rmT \bfS \bfH$ порядка $(K + 1) \times (K + 1)$ не является положительно определённой вследствие размерности матрицы $\bfH$, что существенно сужает множество методов решения задачи квадратичного программирования.

Основная трудность состоит в выборе алгоритма решения задачи. Методы, решающие задачу квадратичного программирования, в основном делятся на два типа: на т.н. ``Active Set'' и ``Interior Point'' методы. Преимущество методов первого типа состоит в том, что они достаточно легко реализуются, дают точное решение за конечное число шагов, но только в том случае, когда матрица квадратичной нормы является положительно определённой \footnote{Процитировать модную книжку}. Interior Point значительно сложнее в реализации, плюс для их работы требуется выбирать некоторые параметры, регулирующие сходимость, что нетривиально.

Ключевой аргумент в пользу Active Set метода --- специфика задачи. Как будет показано позже, для такого метода может быть эффективно подобрана начальная точка и реализована одна итерация.

\subsubsection{Проверка решения неотрицательно определённой задачи}
Предложим быстрый алгоритм, проверяющий, является ли заданный вектор $\widehat C$ точкой, в которой достигается глобальный минимум в задаче \eqref{eq:nonnegatqw}. Для этого применим теорему о необходимом и достаточном условии минимума в задаче квадратичного программирования для задачи \eqref{eq:nonnegatqw}.
\begin{theorem}
	Рассмотрим вектор $R =  \bfH^\rmT \bfS \bfH \widehat C - \bfH^\rmT B = (r_1, \ldots, r_{K+1})^\rmT \in \sfR^{K+1}$. Тогда $\widehat C$ является решением задачи \eqref{eq:nonnegatqw} тогда и только тогда, когда:
	\begin{enumerate}
		\item $R^\rmT \widehat C = 0$,
		\item Существует вектор $U = (u_1, \ldots, u_K)^\rmT \in \sfR^K$ такой, что: \begin{itemize}
			\item $u_i \ge 0$, $i = 1, \ldots, K$,
			\item $u_i \ge -r_i$, $i = 1, \ldots, K$,
			\item $(1 - \alpha) \sum_{i=1}^K u_i \le r_{K+1}$.
		\end{itemize}
	\end{enumerate}
\end{theorem} \label{th:nonnegatfc}
\begin{proof}
	Прямое применение теоремы \footnote{теорема Куна-Таккера} из \footnote{модная книжка по квадратичному программированию. В русской статье можно не мучиться и сослаться на Гавурина-Малоземова} к задаче \eqref{eq:nonnegatqw} с линейными ограничениями \eqref{eq:nonnegatqw_cond}.
\end{proof}

Рассмотрим следующий алгоритм, использующий теорему \ref{th:nonnegatfc} в качестве обоснования.
\begin{algorithm}
	\label{alg:nonnegatfc}
	\textbf{Вход}: предполагаемое решение $\widehat C$, параметр $\alpha$.
	
	\textbf{Результат}:
	Булево значение: является ли $\widehat C$ решением задачи \eqref{eq:nonnegatqw}.
	
	\begin{enumerate}
		\item Вычислить $R = \bfH^\rmT \bfS \bfH \widehat C - \bfH^\rmT B$.
		\item Если $R^\rmT \widehat C \neq 0$, то вернуть ложный ответ, иначе перейти к следующему пункту.
		\item Выбрать в качестве вектора $U = (u_1, \ldots, u_K)$ следующие значения: $u_i = \max(0, -r_i)$, $i = 1, \ldots, K$.
		\item Если $(1 - \alpha) \sum_{i=1}^K u_i \le r_{K+1}$, то вернуть положительный ответ, иначе ложный.
	\end{enumerate}
\end{algorithm}

	Прокомментируем последние два шага алгоритма. В третьем пункте $u_i$ выбираются так, чтобы удовлетворять всем условиям теоремы, кроме последнего условия $(1 - \alpha) \sum_{i=1}^K u_i \le r_{K+1}$. При этом очевидно, что выбор делается так, чтобы сумма $(1 - \alpha) \sum_{i=1}^K u_i$ достигала своего минимума. Если же последнее условие не выполнено, то любой иной выбор $u_i$, удовлетворяющий последнему условию, приведёт к нарушению предыдущих ограничений.

\subsection{Случай нормы $\|X\|_2$: положительно определённые задачи}
Как уже было сказано ранее, задача \eqref{eq:nonnegatqw} нас не устраивает в своей прямой формулировке с точки зрения методов ее решения. Тем не менее, задачу \eqref{eq:nonnegatqw} можно заменить эквивалентной, которая сводится к последовательному решению множества задач квадратичного программирования с положительно определённой матрицей квадратичной нормы.
\subsubsection{$j$-я положительно определённая задача нахождения оптимальных весов}
Сделаем дополнительное предположение: пусть в точке $j$ веса достигают своего максимума, то есть $\hat c_j = 0$. Для того, чтобы избавиться от лишней переменной (с целью получения положительной определённости у матрицы квадратичной нормы), введём новые обозначения.

Рассмотрим вектор $\widetilde C_j = (\tilde c_1, \ldots, \tilde c_{j-1}, \tilde c_\text{max}, \tilde c_{j+1}, \ldots, \tilde c_K)^\rmT \in \sfR^K$, связанный с вектором $C$ следующим соотношением:

\begin{equation} \label{eq:h_jmatrix} C = \bfH_j \widetilde C_j, \quad
\bfH_j = \left(
\begin{array}{ccccccc}
-1 &  &  & 1 &  &  &  \\ 
& \ddots &  & \vdots &  &  &  \\ 
&  & -1 & 1 &  &  &  \\ 
&  &  & 1 &  &  &  \\ 
&  &  & 1 & -1 &  &  \\ 
&  &  & \vdots &  & \ddots &  \\ 
&  &  & 1 &  &  & -1
\end{array} 
\right),
\end{equation}
где столбец из единиц стоит на $j$-м месте, $\bfH_j \in \sfR^{K \times K}$.

Тогда задача нахождения оптимальных весов для заданного индекса $j$ записывается следующим образом:
\begin{gather}\label{eq:j_positqw}
f_j(\widetilde C_j)=\frac{1}{2} \widetilde C_j^\rmT  \bfH_j^\rmT \bfS \bfH_j \widetilde C_j - B^\rmT \bfH_j  \widetilde C_j \to \min_{\tilde c_\text{max}, \, \tilde c_1, \ldots, \tilde c_{j-1}, \tilde c_{j+1}, \ldots, \tilde c_K} \quad \text{при условиях} \\
\label{eq:j_positqw_cond}
\tilde c_\text{max} \ge 0, \quad \tilde c_i \ge 0, \quad (1 - \alpha) \tilde c_\text{max} - \tilde c_i \ge 0, \quad i = 1, \ldots, j-1, j+1, \ldots, K.
\end{gather}
Ясно, что матрица $\bfH_j^\rmT \bfS \bfH_j$ является положительно определённой ($\bfS$ --- положительно определена, $\bfH_j$ --- матрица полного ранга), поэтому для решения задачи \eqref{eq:j_positqw} могут быть применены ``active set'' методы.
\subsubsection{Эквивалентная задача нахождения оптимальных весов}
Точка $j$, в которой достигается максимальный вес, заранее неизвестна. Поэтому задача \eqref{eq:j_positqw} не является эквивалентной задаче \eqref{eq:nonnegatqw}. Построим эквивалентную задачу, использующую решение задачи \eqref{eq:j_positqw} при различных $j$:

\begin{equation}\label{eq:positw}
f_j = f_j(\widetilde C_j^*) \to \min_{j = 1, \ldots, K},
\end{equation}
 где $\widetilde C_j^*$ --- решение задачи \eqref{eq:j_positqw} с индексом максимального веса $j$.
 
То есть, чтобы решить задачу \ref{eq:positw}, необходимо подобрать такой индекс $j$, при котором $f_j(\widetilde C_j^*)$ достигает минимума, после чего в качестве ответа взять $C = \bfH_j \widetilde C_j^*$.
\begin{theorem} \label{th:eqivqw}
	Задачи \eqref{eq:nonnegatqw} и \eqref{eq:positw} эквивалентны.
\end{theorem}
\begin{proof}
	Для доказательства эквивалентности нужно показать, что по индексу $j$ можно построить вектор $\widehat C$ такой, что $f_j \ge f(\widehat C)$, и наоборот: по вектору $\widehat C$ найти такой индекс $j$, что $f(\widehat C) \ge f_j$.
	
	Рассмотрим оба пункта доказательства.
	\begin{enumerate}
		\item Пусть $j$ --- индекс максимального веса, $\widetilde C_j = \widetilde C_j^*$ --- решение соответствующей задачи \eqref{eq:j_positqw}. Тогда рассмотрим следующий вектор $\widehat C$: $\hat c_i = \tilde c_i$, $i = 1, \ldots, j-1, j+1, \ldots, K$, $c_\text{max} = \tilde c_\text{max}$, $\hat c_j = 0$. Так как по построению $\bfH_j \widetilde C_j = \bfH \widehat C$, то целевые функции равны. Выполнение свойств \eqref{eq:nonnegatqw_cond} очевидным образом следует из условий \eqref{eq:j_positqw_cond}.
		\item Вначале рассмотрим вектор $\widehat C$, и найдём такой индекс $j$ и вектор $\widetilde C_j$, что $f(\widehat C) = f_j(\widetilde C_j)$. В качестве $j$ возьмём $j = \argmax_i c_\text{max} - \hat c_i$. Тогда $\tilde c_\text{max} = c_\text{max} - \hat c_j$, а $\tilde c_i = \tilde c_\text{max} - c_\text{max} + \hat c_i = \hat c_i - \hat c_j$, $i = 1, \ldots, j-1, j+1, \ldots, K$. Заметим, что $\tilde c_\text{max} \le c_\text{max}$. Из того, что $c_i = c_\text{max} - \hat c_i = c_\text{max} - \hat c_j + \hat c_j - \hat c_i = \tilde c_\text{max} + \hat c_j - \hat c_i =$ $\tilde c_\text{max} - \tilde c_i$, что эквивалентно $\bfH_j \widetilde C_j = \bfH \widehat C$, следует равенство целевых функций задачи \eqref{eq:nonnegatqw} и вспомогательной задачи \eqref{eq:j_positqw}.
		
		Покажем, что $\tilde c_\text{max} \ge 0$. $\tilde c_\text{max} = c_\text{max} - \hat c_j \ge \hat c_j (1/(1 - \alpha) - 1) \ge 0$, если $\alpha < 1$. Если же $\alpha = 1$, то все $\hat c_i = 0$, и $\tilde c_\text{max} = c_\text{max} \ge 0$. $\tilde c_i \ge 0$, $i = 1, \ldots, K$, $i \neq j$ следует из того, что $\hat c_j$ --- минимальное среди всех $\hat c_i$, $i = 1, \ldots, K$. Последние неравенства проверяются следующим способом: $(1 - \alpha) \tilde c_\text{max} - \tilde c_i = (1 - \alpha)(c_\text{max} - \hat c_j) - \hat c_i + \hat c_j = $ $(1 - \alpha)c_\text{max} - \hat c_i + \alpha \hat c_j \ge 0$.
		
		Заметим, что $f_j = f_j(\widetilde C_j^*) \le f_j(\widetilde C_j)$, что и требовалось доказать.
	\end{enumerate}
\end{proof}

\subsubsection{Алгоритм нахождения оптимальных весов}
Используя теорему об эквивалентности \ref{th:eqivqw}, получаем следующий алгоритм решения задачи \eqref{eq:positw} нахождения оптимальных весов.
\begin{algorithm}
	\label{alg:solveqw}
	\textbf{Вход}: Параметры $L$, $K$, $\alpha$.
	
	\textbf{Результат}:
	Вектор оптимальных весов $C$.
	
	\begin{enumerate}
		\item Положить $j$ = 1.
		\item Решить задачу \eqref{eq:j_positqw} при заданном индексе максимального веса $j$ используя ``Active Set'' метод.
		\item Вычислить эквивалентный вектор $\widehat C$, используя первый пункт теоремы \ref{th:eqivqw}.
		\item Используя Алгоритм \ref{alg:nonnegatfc} проверить, является ли вектор $\widehat C$ решением задачи \eqref{eq:nonnegatqw}. Если да, то положить $C = \bfH \widehat C$, иначе увеличить j на единицу и перейти к пункту 2.
	\end{enumerate}
\end{algorithm}

Таким образом, если встретится нужный индекс $j$, то алгоритму не понадобится перебирать оставшиеся индексы и решать задачу \eqref{eq:j_positqw} лишний раз. Как это будет показано в Разделе \footnote{ссылка}, в практических экспериментах максимальный вес всегда находится на краях, то есть Алгоритм \ref{alg:solveqw} останавливается уже при $j = 1$.
\end{document}
