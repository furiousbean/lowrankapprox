\documentclass[12pt,a4paper,fleqn,leqno]{article}
\usepackage{mathtext}
\usepackage{cmap}
\usepackage[utf8x]{inputenc}
\usepackage[russian]{babel}
\usepackage[T2A]{fontenc}
\usepackage{amsmath,amssymb,amsthm,amscd,amsfonts}
\usepackage{euscript}
\usepackage{relsize}
\usepackage{mathdots}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{caption2}
\usepackage{indentfirst}
\usepackage{fancyhdr}
\usepackage{sectsty}
\usepackage{titlesec}
\usepackage{sicpro_rus}
\usepackage{mathtext}%русские буквы в формулах

\usepackage[colorlinks, urlcolor=blue, pdfborder={0 0 0 [0 0]}]{hyperref}

\hyphenation{Struc-tu-red}
\hyphenation{Ran-do-mized}
\hyphenation{Ma-xi-mi-za-tion}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\tr}{tr}

\def\rank{\mathop{\mathrm{rank}}}
%\newtheorem{definition}{Определение}%[section]
\newtheorem{proposition}{Утверждение}%[section]
\newtheorem{algorithm}{Algorithm}%[section]

\input{letters}

%\input{letters_series_mathbb}
\input{newcommands}
%\input{newcommands2dssa}


\sectionfont{\centering}

\subsectionfont{\centering}
\subsubsectionfont{\normalsize}
\setcounter{page}{1}


\author{Звонарев Никита}
\title{Итеративные алгоритмы взвешенной аппроксимации рядами конечного ранга}
\begin{document}
\noindent УДК 519.246.8+519.254

\begin{center}{
\fontsize{18pt}{23pt}\selectfont\bf%
  \MakeUppercase{
 Итеративные алгоритмы взвешенной аппроксимации рядами конечного ранга
}}
\end{center}

\begin{center}{\bpv\bmv {Н.К.~Звонарев}\\
\footnotesize\it Санкт-Петербургский государственный университет,\\
Математико-механический факультет
\\
\rm
Россия, 198504, Санкт-Петербург, Петродворец, Университетский пр., 28\\
E-mail: \textcolor {blue}{\underline{mb\_93@mail.ru}}}
\end{center}
\begin{center}{\bpv {Н.Э.~Голяндина}\\
\footnotesize\it Санкт-Петербургский государственный университет,\\
Математико-механический факультет
\\
\rm
Россия, 198504, Санкт-Петербург, Петродворец, Университетский пр., 28\\
E-mail: \textcolor {blue}{\underline{nina@gistatgroup.com}}}
\end{center}
\hspace{1.25cm}\begin{minipage}{12.16cm}\bpv\bpv\bmv \noindent
\footnotesize{\bf Ключевые слова:}\/ Временные ряды, алгоритм Cadzow, косоугольное SVD-разложение, SSA

\bpv\bpv\noindent  В работе рассматриваются вопросы аппроксимации временного ряда рядами конечного ранга. Эта задача возникает в задачах обработки сигналов, в частности, при анализе зашумленных сигналов. В работе рассматривается постановка задачи аппроксимации, т.е. нахождения ряда конечного ранга, ближайшего к исходному. Возникает оптимизационная задача, в которой целевая функция, судя по всему, имеет много локальных минимумов. Один из методов локального поиска (итерации Cadzow) уже хорошо известен, и описан в данной работе. Целевая функция имеет вид взвешенного евклидова расстояния, однако, итерации Cadzow могут работать только с весами специфичного вида, в то время как зачастую требуются именно единичные веса, порождающие обычную евклидову метрику, поэтому были построены и рассмотрены несколько новых методов, подход которых состоит в том, чтобы добиться единичных или близких к ним весов. Для всех методов было произведено сравнение на модельных примерах, из которого видно преимущество новых алгоритмов в задаче оценки зашумленного сигнала, по сравнению с обычными итерациями Cadzow.

\end{minipage}\bls\bmv

\section{Введение}
\addcontentsline{toc}{section}{Введение}
Рассмотрим задачу выделения сигнала $\tsY = (y_1, \ldots, y_N)$ из наблюдаемого зашумлённого сигнала $\tsX = \tsY + \tsN$, где $\tsY$  обладает некоторой заданной структурой, а именно, $\tsY$ управляется некоторой \emph{линейной рекуррентной формулой} (ЛРФ) порядка $r$:
\begin{equation*}
y_n = \sum_{i = 1}^{r} a_i y_{n-i}, \quad n = r + 1, \ldots, N.
\end{equation*}
Вообще говоря, ряды, управляемые ЛРФ, могут быть записаны в параметрической форме в виде $y_n = \sum_i P_i(n) \exp(\alpha_i n) \cos(2 \pi \omega_i n + \psi_i)$. Однако, параметрический подход к задаче не приводит к хорошим оценкам, так как параметров много, и их оценки неустойчивы.

Хорошо зарекомендовали себя так называемые \emph{subspace-based} методы. Идея таких методов следующая: зафиксируем длину окна $L$, $1 \le L \le N$, $K = N - L + 1$, и построим по ряду $\tsY$ траекторную матрицу
\begin{equation*}
\bfY = \begin{pmatrix}
y_1 & y_2 & \ldots & y_K \\
y_2 & y_3 & \ldots & y_{K + 1} \\
\vdots & \vdots & \vdots & \vdots \\
y_L & y_{L + 1} & \ldots & y_N
\end{pmatrix}.
\end{equation*}
Если ряд управляется минимальной ЛРФ порядка $r$, $r < \min(L, K)$, то $\text{rank} \bfY = r < L$. Таким образом, $\bfY$ --- ганкелева матрица ранга $r$.

Пусть $\bfX$ --- траекторная матрица ряда $\tsX$. Тогда задачу оценивания $\tsY$ можно рассматривать как задачу аппроксимации матрицы $\bfX$ ганкелевой матрицей ранга $\le r$:
\begin{equation}\label{introd_task}
||\bfY - \bfX||^2_F \to \min_{\substack{\text{rank} \bfY \le r \\ \bfY \in \calH}}
\end{equation}

Этой задаче посвящено много работ, например, \cite{Cadzow1988}, \cite{Gillard2014}. Методы решения --- итеративные, например, метод Cadzow состоит из альтернативных проекций на множество ганкелевых матриц и матриц ранга $\le r$. Хотя целевая функция не унимодальная, и сходимость к глобальному минимуму не гарантируется, тем не менее, задача \eqref{introd_task} считается достаточно хорошо исследованной.

Заметим, что задача \eqref{introd_task} эквивалента задаче
\begin{equation}\label{introd_task_2}
\sum_{i = 1}^n w_i(x_i - y_i)^2 \to \min_{\substack{\tsY: \rank \bfY \le r \\ \bfY \in \calH}},
\end{equation}
\begin{equation*}
\text{где} \quad w_i = \begin{cases}
i & \text{для $i = 1, \ldots, L-1,$}\\
L & \text{для $i = L, \ldots, K,$}\\
N - i + 1 & \text{для $i = K + 1, \ldots, N.$}
\end{cases}.
\end{equation*}

На краях ряда вес меньше, чем в середине, то есть \eqref{introd_task_2} является задачей взвешенного МНК для ряда (заметим, что чем меньше $L$, тем ближе веса к равномерным).

Целью данной работы было рассмотреть методы, решающие задачу \eqref{introd_task_2} c равными весами $w_i$, и сравнить результаты с точки зрения точности оценивания сигнала $\tsY$. Все рассматриваемые методы являются итерационными. Если интерес представляет оценка сигнала, которая не обязательно управляется ЛРФ, то в качестве оценки сигнала можно брать первую итерацию с целью уменьшения трудоёмкости. Таким образом, рассматриваемые методы сравнивались по точности оценки сигнала на первой итерации и в пределе. Заметим, что известный метод Singular Spectrum Analysis (SSA) \cite{Golyandina.Zhigljavsky2012} можно
рассматривать как одну итерацию метода Cadzow.

\section{Аппроксимация ганкелевыми матрицами неполного ранга}
\subsection{Общий алгоритм}
Рассмотрим задачу аппроксимации матрицы ганкелевой матрицей неполного ранга по некоторой (полу)норме $\|\cdot\|$.
Обозначим $\spaceR^{L\times K}$ пространство матриц размер $L$ на $K$, $\calM_r\subset \spaceR^{L\times K}$ множество матриц ранга, не превосходящего $r$,
$\calН \spaceR^{L\times K}$ --- множество ганкелевых матриц.
Заметим, что  $\calM_r$ не является линейным и даже не выпуклым множеством. Однако, $\calM_r$ является мультипликативным, т.е.
если $\bfX\in \calM_r$, то и $a\bfX\in \calM_r$ для любого $a$.
Пространство $\calН$ является линейным.

Задача имеет вид
\be
\label{eq:gen_task}
||\bfX - \bfY|| \to \min_\bfY, \mbox{\ где\ } \bfY \in \calH \cap \calM_r.
\ee

Чтобы привести схему алгоритма для решения данной задачи, введем проекторы на соответствующие подпространства
по норме $\|\cdot\|$, $\Pi_r$ --- проектор на $\calM_r\subset \spaceR^{L\times K}$. Оба проектора являются ортогональными,
так как для ортогональности достаточно того, чтобы пространство было мультипликативным. Заметим, что результат проектирования
на пространство матриц неполного ранга может быть неоднозначно определен, однако в дальнейшем будет предполагать, что
в случае неоднозначности выбрано произвольное значение из допустимых.

\begin{proposition} \label{pythaprop}
Пусть $X$ --- гильбертово пространство, $\calM$ --- замкнутое относительно умножения на скалярную величину подмножество ($x \in \calM \Rightarrow \alpha x \in \calM \, \forall \alpha \in \sfR$), $\Pi_\calM$ --- оператор проектирования на $\calM$ \footnote{На самом деле, проекция может быть определена неоднозначно, но дальше будем предполагать, что оператор однозначен. В данном случае, можно выбирать любой вариант для проекции, это никак не влияет на истинность утверждений.}. Тогда для любого $x \in X$ выполняется теорема Пифагора: $||x||^2 = ||x - \Pi_\calM x||^2 + ||\Pi_\calM x||^2$.
\end{proposition}
\begin{proof}
Представим множество $\calM$ в виде $\calM = \bigcup\limits_{l \in L}l$, где $L$ --- множество всех прямых, лежащих в $\calM$ и проходящих через $0$, и $l \cap m = 0$ для любых $l, m \in L$, $l \neq m$. Тогда операция проектирования может быть записана так: вначале мы выбираем прямую $l$ такую, что $\text{dist}(x, l) \rightarrow \min\limits_{l \in L}$, после чего $y = \Pi_\calM x$ --- это проекция $x$ на $l$. Получаем нужное свойство.
\end{proof}

Для решения задачи \eqref{eq:gen_task} можно использовать итеративный метод альтернативных проекций в виде
\be
   \bfY_{k+1}=\Pi_\calH \Pi_{\calM_r} \bfY_{k}, \mbox{\ где\ } \bfY_{0}=\bfX.
\ee

Докажем теорему относительно сходимости данного метода.

\begin{theorem}
\label{th:converg}
\begin{enumerate}
Пусть пространство $\calM_r$ является замкнутым в топологии, порождаемой нормой $\|\cdot\|$. Тогда
\item $||\bfX_k - \Pi_{\calM_r}\bfX_k|| \to 0$ при $k \to +\infty$, $||\Pi_{\calM_r}\bfX_k - \bfX_{k+1}|| \to 0$ при $k \to +\infty$.
\item Существует сходящаяся подпоследовательность $\bfX_{i_1}, \bfX_{i_2}, \ldots$ такая, что её предел $\bfX^*$ лежит в $\calM_r \cap \calH$.
\end{enumerate}
\end{theorem}
\begin{proof}
Воспользуемся неравенствами \cite{Chu.etal2003}
\begin{equation}
\label{chuprop}
||\bfX_k - \Pi_{\calM_r} \bfX_k|| \ge ||\Pi_{\calM_r} \bfX_k - \bfX_{k + 1}|| \ge ||\bfX_{k+1} - \Pi_{\calM_r} \bfX_{k + 1}||.
\end{equation}

\begin{enumerate}
\item Согласно неравенствам \eqref{chuprop}, последовательности $||\bfX_k - \Pi_{\calM_r} \bfX_k||$, $k = 1, 2, \ldots$, и $||\Pi_{\calM_r} \bfX_k - \bfX_{k + 1}||$, $k = 1, 2, \ldots$ являются невозрастающими. Очевидно, они ограничены снизу нулём. Поэтому они имеют одинаковый предел $c$, опять же согласно \eqref{chuprop}.

Докажем, что $c = 0$. Предположим противное: существует $d > 0$ такое, что для любого $k = 1, 2, \ldots$: $||\bfX_k - \Pi_{\calM_r} \bfX_k|| > d$, $||\Pi_{\calM_r} \bfX_k - \bfX_{k + 1}|| > d$. Согласно утверждению \ref{pythaprop}, справедливо следующее:
\begin{gather*}
||\bfX_k||^2 = ||\Pi_{\calM_r} \bfX_k||^2 + ||\bfX_k - \Pi_{\calM_r} \bfX_k||^2 =\\ ||\bfX_k - \Pi_{\calM_r} \bfX_k||^2 + ||\Pi_{\calM_r} \bfX_k - \bfX_{k + 1}||^2 + ||\bfX_{k + 1}||^2.
\end{gather*}
Таким образом, $||\bfX_{k+1}||^2 < ||\bfX_k||^2 - 2d^2$. Расписывая неравенство аналогично дальше, получим, что для любого $j = 1, 2, \ldots$: $||\bfX_{k+j}||^2 < ||\bfX_k||^2 - 2 j d^2$. Возьмём любое $k$, например $k = 1$, и $j = \lceil ||\bfX_k||^2 / (2d^2) \rceil + 1$. Тогда $||\bfX_{k+j}||^2 < 0$, чего не может быть.
\item Рассмотрим последовательность $(\Pi_{\calM_r} \bfX_k)$, $k = 1, 2, \ldots$. Она ограничена, так как $||\Pi_{\calM_r} \bfY|| \le ||\bfY||$ и $||\Pi_{\calH} \bfY|| \le ||\bfY||$ для любого $\bfY \in \sfR^{L \times K}$ (это справедливо, например, и по утверждению \ref{pythaprop}). Тогда мы можем выбрать из неё сходящуюся подпоследовательность $(\Pi_{\calM_r} \bfX_{i_k})$, $\bfX^*$ --- её предел, при этом $||\Pi_{\calM_r} \bfX_{i_k} - \bfX_{i_k + 1}|| = ||\Pi_{\calM_r} \bfX_{i_k} - \Pi_\calH \Pi_{\calM_r} \bfX_{i_k}|| \to 0$ при $k \to + \infty$. Учитывая, что $||\bfY - \Pi_\calH \bfY||$ --- композиция непрерывных отображений, получаем, что $||\bfX^* - \Pi_\calH \bfX^*|| = 0$ и зная, что $\calM_r$ --- замкнутое множество, получаем, что $\bfX^* \in \calM_r \cap \calH$. Осталось увидеть, что последовательность $(\Pi_\calH \Pi_{\calM_r} \bfX_{i_k})$ --- сходящаяся, так как $\Pi_\calH$ --- непрерывное отображение, и ее предел равен $\bfX^*$. Получаем, что $\bfX_{i_k + 1}$ --- требуемая подпоследовательность.
\end{enumerate}
\end{proof}

TODO: про поправки в общем виде?

Ниже мы будем рассматривать нормы, порождённые взвешенным фробениусовым скалярным произведением в виде
\be
\label{eq:w_inner_prod}
\langle\bfX, \bfY\rangle_M = \sum_{l = 1}^L \sum_{k = 1}^K m_{l, k} x_{l, k} y_{l, k}.
\ee

Относительно такой нормы пространство $\calM_r$ является замкнутым и, следовательно, утверждения теоремы~\ref{th:converg} верны.

\subsection{Вычисление проекторов}

Будем рассматривать норму $\|\cdot\|_\bfM$, порождённую \eqref{eq:w_inner_prod}.

\paragraph{Проектор $\Pi_\calH$.} Несложно показать, что проектор $\Pi_\calH$
можно вычислить явным образом согласно следующему утверждению.

\begin{proposition}
Для $\widehat{\bfY}=\Pi_\calH \bfX$
\begin{equation*}
\hat{y}_{ij} = \frac{\sum_{l,k: l+k=i+j} m_{l,k} x_{l,k}}{\sum_{l,k: l+k=i+j} s_{l,k}}.
\end{equation*}
\end{proposition}

Явный вид проектора $\Pi_{\calM_r}$ в общем случае не получить.
Рассмотрим различные случаи.

\paragraph{Случай явного вида проектора $\Pi_{\calM_r}$.} Сначала рассмотрим случай, когда проектор можно выписать явно.
Хорошо известно, что если все веса $m_{ij}$ равны 1, то проектор $\Pi_{\calM_r} \bfX$
вычисляется как сумма первых компонент сингулярного разложения матрицы $\bfX$.
Обозначим этот проектор как $\Pi_r$.
Следующее утверждение описывает случаи, когда нахождение проектора
сводится к применению оператора $\Pi_r$.  (TODO: Написать формально, какой вид через SVD?)

\begin{proposition}
\label{prop:projS}
Пусть существует симметричная, неотрицательно определённая матрица  $\bfS$ порядка $K \times K$,
такая что $\|\cdot\|_\bfM = \tr(\bfX \bfS \bfX^\rmT)$.
Предположим также, что пространство столбцов матрицы $\bfX$ лежит в пространстве столбцов матрицы $\bfX$.
Тогда $\Pi_{\calM_r} \bfX = (\Pi_r \bfB) (\bfO_\bfS^{\rmT})^\dagger$, где $\bfO_\bfS$ --- такая матрица, что $\bfS = \bfO_\bfS^{\rmT}\bfO_\bfS$,
$\bfB = \bfX \bfO_\bfS^{\rmT}$, $(\bfO_\bfS^{\rmT})^\dagger$ обозначает псевдообратную матрицу Мура-Пенроуза к матрице $\bfO_\bfS^{\rmT}$.
\end{proposition}
\begin{proof}
Доказательство является прямым следствием того, что рассматриваемая норма порождается косоугольным скалярным произведением в пространстве строк матрицы $\bfX$, см. детали в \cite{Golyandina2013}.
\end{proof}

\begin{remark}
Заметим, что условия утверждения~\ref{prop:projS} могут быть выполнены только если матрица $\bfS$ диагональная.
\end{remark}

\paragraph{Проектор $\Pi_{\calM_r}$ в общем случае.}
Так как в явном виде проектор не находится, то в общем случае используются итеративные алгоритмы.
Один из них описан в \cite{Srebro2003}

\begin{algorithm}
\label{alg:weightedSVD}
\textbf{Вход}: исходная матрица $\bfX$, ранг $r$, матрица весов $\bfM$,
критерий остановки STOP (например, число итераций Q).

\textbf{Результат}:
Матрица $\widehat\bfY$ как оценка $\Pi_{\calM_r} \bfX$.

\begin{enumerate}
\item
$\bfY_0 = \bfX$, $k=0$.
\item
$\bfY_{k+1} = \Pi_r(\bfX \odot \bfM + \bfY_{k} \odot (\bfU -  \bfM))$, где
$\bfU \in \sfR^{L \times K}$,  $\bfU = \begin{pmatrix}
1 & \cdots & 1 \\
\vdots & \ddots & \vdots \\
1 & \cdots & 1
\end{pmatrix}$, $k\leftarrow k+1$.
\item
Если STOP, то $\widehat\bfY = \bfY_k$.
\end{enumerate}
\end{algorithm}

Заметим, что в случае, когда $m_{ij}$ равняется 0 или 1, алгоритм является EM-алгоритмом \cite{Srebro2003},
соответственно, для него выполнены свойства EM-алгоритмов и он сходится к локальному минимуму в задаче поиска проектора.
В случае нулевых весов формально неважно, какие значения стоят в матрице на этих местах. Однако для сходимости алгоритма
это может быть существенно.

\section{Временные ряды и задача аппроксимации матриц}
\footnote{Сюда скопировала материал, но не правила}
\subsection{Постановка задачи для временных рядов}
Рассмотрим временной ряд $\tsX = (x_1, \ldots, x_N)$ длины $N \ge 3$. Зафиксируем длину окна $L$, $1 < L < N$, положим $K = N - L + 1$. Также рассмотрим последовательность векторов:
\begin{equation}\label{l_lagged}
X_i = (x_i, \ldots, x_{i + L - 1})^\rmT, \qquad i = 1, \ldots, K.
\end{equation}
\emph{Траекторным пространством} ряда $\tsX$ назовём $$\spX^{(L)}(\tsX) = \spX^{(L)} = \text{span}(X_1, \ldots, X_{N-L+1}).$$

\begin{definition}
Пусть $0 \le r \le L$. Будем говорить, что ряд $\tsX$ \emph{имеет $L$-ранг $r$}, если $\dim \spX^{(L)} = r$.
\end{definition}

Заметим, что ряд $\tsX$ может иметь $L$-ранг $r$ только тогда, когда
\begin{equation}
r \le \min(L, N-L+1). \label{min_condition}
\end{equation}
Скажем, что при фиксированном $r$ длина окна $L$ является \emph{допустимой}, если для неё выполнено условие \eqref{min_condition}.

В дальнейшем будет предполагаться, что $L$ не превосходит $K$, так как транспонирование не изменит ситуацию, а строчный ранг матрицы равен её столбцовому рангу.

Пусть $\sfX_N$ --- множество всех временных рядов длины $N$, $\sfX_N^r$ --- множество всех временных рядов длины $N$ $L$-ранга $r$. Для заданныx $\tsX \in \sfX_N$ --- исходный временной ряд, $1 < L < N$ --- длина окна и $r$, удовлетворяющего условию \eqref{min_condition}, рассмотрим задачу:
\begin{equation} \label{L-rank_task}
f_q(\tsY) \to \min_{\tsY \in \sfX_N^r}, \quad f_q(\tsY) = \sum \limits_{i=1}^N q_i(x_i - y_i)^2,
\end{equation}
где $f_q(\tsY) = \sum \limits_{i=1}^N q_i(x_i - y_i)^2$, $y_i$ --- $i$-е измерение ряда $\tsY$, а $q_1, \ldots, q_N$, $q_i \ge 0$, $i = 1, \ldots, N$ --- некоторые неотрицательные веса. В частном случае, рассматривается целевая функция $f(\tsY) = \rho^2(\tsX, \tsY)$ --- квадрат евклидова расстояния в $\sfR^N$. Она совпадает с $f_q(\tsY)$ при $q_i = 1$, $i = 1, \ldots, N$.
%-------

%\subsection{Отображение на множество ганкелевых матриц}
Пусть $\tsX$ --- временной ряд длины $N$, а $\bfX \in \calH$ --- матрица, где $\calH = \calH^{L \times K}$ --- множество всех ганкелевых матриц размера $L \times K$. Тогда между $\sfX_N$ --- множеством всех временных рядов длины $N$ и $\calH$ можно построить отображение $\calT$, действующее по правилу
\begin{equation*}
\calT(\tsX) = \bfX: \hat x_{l, k} = x_{l + k - 1}, \quad \bfX = (\hat x_{l,k}), \quad \tsX = (x_1, \ldots, x_N).
\end{equation*}
Нетрудно заметить, что это отображение является биективным.

Так как есть взаимно-однозначное соответствие между пространство рядов и ганкелевыми матрицами,
задачу~\eqref{L-rank_task} можно записать на матричном языке.

\subsection{Эквивалентные целевые функции задачи \eqref{L-rank_task}}
В пространстве рядов целевая функция явным образом задаётся через скалярное произведение
\begin{equation}
\label{eq:norm_ser}
    \langle\tsX,\tsY\rangle_q = \sum_{i = 1}^N q_i x_i y_i,
\end{equation}
где $q_i$ --- положительные веса.

Рассмотрим два скалярных произведения в пространстве матриц, являющихся расширениями
обычного фробениусова скалярного произведения.

Введём
\begin{equation}
\label{eq:norm1M}
    \langle\bfX,\bfY\rangle_{1,\bfM} = \sum_{i = 1}^L \sum_{j=1}^K m_{i,j} x_{i,j} y_{i,j}.
\end{equation}
для матрицы $\bfM$ с положительными элементами и
\begin{equation}
\label{eq:norm2S}
    \langle\bfX,\bfY\rangle_{2,\bfS} = \tr(\bfX \bfS \bfY^\rmT)
\end{equation}
для положительно определённой (или неотрицательно определённой для полунормы) матрицы $\bfS$.

Заметим, что если матрица $\bfM$ состоит из всех единиц, т.е. $m_{i.j}=1$,
и если $\bfS$ --- единичная матрица, то оба скалярных произведения совпадают
с обычным фробениусовым.

\begin{proposition}
1. Пусть $\bfX = \calT(\tsX)$,  $\bfY = \calT(\tsY)$. Тогда $\langle\tsX,\tsY\rangle_q= <\bfX,\bfY>_{1,\bfM}$ тогда и только тогда, когда
\begin{equation}\label{qi_mi}
q_i = \sum_{\substack{1 \le l \le L \\ 1 \le k \le K \\ l+k-1=i}} m_{l,k}.
\end{equation}

2. Для диагональной матрицы $\bfS$, $\langle\bfX,\bfY\rangle_{1,\bfM}= \langle\bfX,\bfY\rangle_{2,\bfS}$ тогда и только тогда, когда
\begin{equation}\label{sk_mlk}
m_{l,k}=s_{k,k}.
\end{equation}
\end{proposition}
\begin{proof}
Для доказательства первой части утверждения заметим, что
\begin{equation*}
\langle \bfX, \bfY \rangle_{1,\bfM} = \sum_{i = 1}^L \sum_{j = 1}^K m_{i,j} x_{i + j - 1} y_{i + j - 1},
\end{equation*}
Доказательство второй части следует из того, что для диагональной матрицы $\bfS$
\begin{equation*}
\langle \bfX, \bfY \rangle_{2,\bfS} = \sum_{l=1}^L \sum_{k=1}^K s_{k,k} x_{l,k} y_{l, k}.
\end{equation*}
\end{proof}

Заметим, что вторая матричная норма с диагональной матрицей $\bfS$ является частным случаем первой.
Однако, ценность записи первой нормы в виде
второй состоит в том, что аппроксимация матрицами меньшего ранга по первой норме --- это сложная задача при неединичных весах
$m_{i.j}$, а аппроксиммация по второй норме --- естественная задача, решаемая с помощью косоугольного сингулярного разложения.

\section{Алгоритмы}

\subsection{Алгоритм Cadzow}
Этот алгоритм служит для решения задачи () с весами $m_{ij}=1$, что соответствует задаче
() с весами $w_i$, задаваемыми \ref{}.
Алгоритм был предложен в \cite{Cadzow1988}. Его недостатком является то. что веса $w_i$ не являются равными,
на краях они меньше, чем в середине. Чем меньше длина окна. тем ближе веса к равным.

\begin{algorithm}[Cadzow]
\textbf{Вход}: Временной ряд $\tsX$, длина окна $L$, ранг $r$,
критерий остановки STOP (например, число итераций Q).

\textbf{Результат}:
Ряд $\widehat\tsY$ как оценка аппроксимации $\tsX$ рядом конечного ранга $r$.

\begin{enumerate}
\item
$\bfY_0 = \calT \tsX$, $k=0$.
\item
$\bfY_{k+1} = \Pi_\calH  \Pi_{\calM_r} \bfY_{k}$, $k\leftarrow k+1$.
\item
Если STOP, то $\widehat\tsY = \calT^{-1} \bfY_k$.
\end{enumerate}
\end{algorithm}

\subsection{Алгоритм Weighted Cadzow}

Пусть веса $w_{ij}=1$. Тогда, по утверждению~\ref{}, эквивалентные матричные веса имеют вид $m_{ij}=...$.

\begin{algorithm}[Weighted Cadzow]
\textbf{Вход}: Временной ряд $\tsX$, длина окна $L$, ранг $r$,
критерии остановки STOP1 для внешних итераций и STOP2 для внутренних.

\textbf{Результат}:
Ряд $\widehat\tsY$ как оценка аппроксимации $\tsX$ рядом конечного ранга $r$.

\begin{enumerate}
\item
$\bfY_0 = \calT \tsX$, $k=0$.
\item
Получение $\widehat\bfZ$ по алгоритму~\ref{alg:weightedSVD} с критерием остановки STOP2, примененному к $\bfY_k$ для оценивания $\Pi_{\calM_r} \bfY_{k}$.
\item
$\bfY_{k+1} = \Pi_\calH  \widehat\bfZ$, $k\leftarrow k+1$.
\item
Если STOP1, то $\widehat\tsY = \calT^{-1} \bfY_k$.
\end{enumerate}
\end{algorithm}

\subsection{Алгоритм Extended Cadzow}

Постановка задачи в этом алгоритме несколько отличается от общей постановки задачи.
Формально, мы продлеваем ряд в обе стороны на $L-1$ точек некоторыми значениями, приписывая им вес 0, т.е.
считая их пропусками. Таким образом, расширенный ряд $\widetilde\tsX$ будет иметь длину $N+2L-2$, а его траекторная матрица
$\widetilde\bfX$ будет иметь размер $L$ на $N+L-1$.

Для нового расширенного ряда мы применяем общую схему с весами $m_{ij}=\calT \tsI$, где ряд $\tsI$ имеет 
значения 1 на местах исходного ряда и значения 0 на местах пропусков.
(TODO: поформальнее)

\begin{algorithm}[Extended Cadzow]
\textbf{Вход}: Временной ряд $\tsX$, длина окна $L$, ранг $r$,
критерии остановки STOP1 для внешних итераций и STOP2 для внутренних,
значения, которыми дополнен ряд слева и справа, $\tsL_{L-1}$ и $\tsR_{L-1}$.

\textbf{Результат}:
Ряд $\widehat\tsY$ как оценка аппроксимации $\tsX$ рядом конечного ранга $r$.

\begin{enumerate}
\item
$\bfY_0 = \calT \widetilde\tsX$, $k=0$.
\item
Получение $\widehat\bfZ$ по алгоритму~\ref{alg:weightedSVD} с критерием остановки STOP2, примененному к $\bfY_k$ для оценивания $\Pi_{\calM_r} \bfY_{k}$.
\item
$\widetilde\bfY_{k+1} = \Pi_\calH  \widehat\bfZ$, $k\leftarrow k+1$.
\item
Если STOP1, то $\widehat\tsY = \calT^{-1} \bfY_k$, где $\bfY_k$ состоит из столбцов матрицы $\widetilde\bfY_{k}$
c $L$-го по $N$-й.
\end{enumerate}
\end{algorithm}

\subsection{Алгоритмы Oblique Cadzow}

Эти алгоритмы могут быть применены, если выполнены условия утверждения~\ref{prop:projS}.

Далее алгоритм в общем виде.

Затем частные случаи матрицы S с названиями. Привести вид соотв. весов для ряда.

\subsection{Одна итерация, разделимость и скорость сходимости, как сравнивать алгоритмы}

Про одну итерацию. Про SSA. Про разделимость. 

Про возможное соотношение между скоростью сходимости итерация и разделимостью,
которая характеризует первый шаг.

Про трудоемкость алгоритмов.

(TODO: пока выглядит как винегрет)

\section{Численные эксперименты}

Сравнение на одном шаге

Сравнение в пределе

Зависимость результата от $L$

Зависимость от $\alpha$

Скорость сходимости

\section{Заключение}
Были предложены новые алгоритмы и исследованы старые.

Доказательство сходимости в общей форме.

Сравнение алгоритмов с пом. числ. моделирования.
Показало, что ...

\section{Приложение: Разделимость двух гармоник для алгоритма Cadzow($\alpha$)}
 
\bibliographystyle{plain}
\bibliography{ssa2012}
\end{document}
